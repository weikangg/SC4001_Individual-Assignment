{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "\n",
    "import time  # For time-related functions\n",
    "import pandas as pd  # For data manipulation\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "import torch  # For PyTorch deep learning framework\n",
    "from torch.utils.data import DataLoader  # For data loading\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # For feature scaling\n",
    "from sklearn.model_selection import KFold  # For data splitting\n",
    "\n",
    "# Import custom utility functions\n",
    "from common_utils import set_seed, split_dataset, EarlyStopper, train_one_epoch, evaluate_model\n",
    "\n",
    "# Set a specific random seed for reproducibility\n",
    "SEED = 0\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP, CustomDataset, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e431e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbc3549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "pos    6202\n",
      "neg    5855\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset from a CSV file.\n",
    "df = pd.read_csv('simplified.csv')\n",
    "set_seed()\n",
    "\n",
    "# Extracting the 'label' from the 'filename' column.\n",
    "# It appears the label is embedded in the filename and is the penultimate (second last) item when split by '_'.\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "\n",
    "# Checking the distribution of the labels.\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Dropping Unnecessary Columns and Splitting the Dataset:\n",
    "# The dataset column called filename is likely a unique identifier for each sample and not a feature we would use for modeling. Hence, we should remove it before feeding the data to our model. \n",
    "columns_to_drop = ['filename', 'label']  \n",
    "\n",
    "# Splitting the dataset into training and testing sets:\n",
    "# The split is done in a 70:30 ratio, and the random_state ensures reproducibility.\n",
    "# We still do train-test split here because the question specifies us to use 5-fold cross-validation on the training partition and not the whole dataset.\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, columns_to_drop, test_size=0.3, random_state=SEED)\n",
    "\n",
    "'''\n",
    "In the context of 5-fold cross-validation, \"reconsidering the scaling\" likely means we should be applying scaling within each fold of the cross-validation, rather than fitting a scaler on the entire training dataset beforehand. \n",
    "In each fold of the 5-fold cross-validation, a portion of our training set becomes the \"validation\" set, so the scaling parameters might be slightly different for each fold.\n",
    "\n",
    "As such, for our k-fold cross-validation procedure, the steps would be as follows:\n",
    "\n",
    "The original training dataset is split into k subsets (folds).\n",
    "For each k:\n",
    "    Take the k-th fold as the validation set, and the remaining k-1 folds as the training set.\n",
    "    Fit the scaler only on this new training set.\n",
    "    Transform both the training and validation sets using this scaler.\n",
    "    Train the model on the scaled training set.\n",
    "    Validate the model on the scaled validation set.\n",
    "'''\n",
    "\n",
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # Dictionary Initializations\n",
    "    X_train_scaled_dict = {}  # Dictionary to store scaled training data\n",
    "    X_val_scaled_dict = {}    # Dictionary to store scaled validation data\n",
    "    y_train_dict = {}         # Dictionary to store training labels\n",
    "    y_val_dict = {}           # Dictionary to store validation labels\n",
    "\n",
    "    # Create a 5-fold cross-validation object with shuffling\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Loop through different batch sizes\n",
    "    for batch_size in parameters:\n",
    "        X_train_scaled_folds = []  # List to store scaled training data for each fold\n",
    "        X_val_scaled_folds = []    # List to store scaled validation data for each fold\n",
    "        y_train_folds = []         # List to store training labels for each fold\n",
    "        y_val_folds = []           # List to store validation labels for each fold\n",
    "\n",
    "        # Loop through each fold\n",
    "        for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "            X_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "            X_val_fold, y_val_fold = X_train[val_idx], y_train[val_idx]\n",
    "\n",
    "            # Scaling the data using StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "            X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "            # Append data to respective lists\n",
    "            X_train_scaled_folds.append(X_train_fold_scaled)\n",
    "            X_val_scaled_folds.append(X_val_fold_scaled)\n",
    "            y_train_folds.append(y_train_fold)\n",
    "            y_val_folds.append(y_val_fold)\n",
    "\n",
    "        # Store data for this batch size in dictionaries\n",
    "        X_train_scaled_dict[batch_size] = X_train_scaled_folds\n",
    "        X_val_scaled_dict[batch_size] = X_val_scaled_folds\n",
    "        y_train_dict[batch_size] = y_train_folds\n",
    "        y_val_dict[batch_size] = y_val_folds\n",
    "\n",
    "    # Return the dictionaries containing data for different batch sizes\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "set_seed(SEED)  # Set a specific random seed for reproducibility\n",
    "batch_sizes = [128, 256, 512, 1024]  # List of batch sizes to generate folds for\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235ca332-9676-42bd-9801-0f5f4157a777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dictionaries to hold the DataLoaders for training and validation datasets for each batch size.\n",
    "set_seed(SEED)\n",
    "train_loaders_dict = {}\n",
    "val_loaders_dict = {}\n",
    "\n",
    "# Loop through each batch size we're considering\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    # Lists to store DataLoaders for the current batch size for each of the 5 folds\n",
    "    train_loaders = []\n",
    "    val_loaders = []\n",
    "\n",
    "    # Loop through each fold (0 through 4 for 5-fold CV)\n",
    "    for i in range(5):\n",
    "        \n",
    "        # Create a PyTorch Dataset for the training data for the current fold. The CustomDataset will convert our data into a format that PyTorch can work with.\n",
    "        train_dataset = CustomDataset(X_train_scaled_dict[batch_size][i], y_train_dict[batch_size][i])\n",
    "        \n",
    "        # Similarly, create a PyTorch Dataset for the validation data for the current fold.\n",
    "        val_dataset = CustomDataset(X_val_scaled_dict[batch_size][i], y_val_dict[batch_size][i])\n",
    "\n",
    "        # Create a DataLoader for the training dataset. This DataLoader will allow us to efficiently iterate over data in mini-batches of size 'batch_size'.\n",
    "        # We shuffle the training data to ensure the order is different each epoch.\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Create a DataLoader for the validation dataset. There's no need to shuffle validation data as we typically just evaluate performance on it.\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Append the created DataLoaders to our lists.\n",
    "        train_loaders.append(train_loader)\n",
    "        val_loaders.append(val_loader)\n",
    "\n",
    "    # Store the lists of DataLoaders in our dictionaries with the current batch size as the key. This way, when we need to access the DataLoader for a specific fold and batch size, we can easily retrieve it.\n",
    "    train_loaders_dict[batch_size] = train_loaders\n",
    "    val_loaders_dict[batch_size] = val_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a489ddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Starting with batch_size: 128 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:06<00:33,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7115, Time: 0.3646 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:14<00:36,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.7488, Time: 0.5045 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:08<00:42,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 18 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.6943, Time: 0.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:09<00:31,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.7316, Time: 0.5443 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:06<00:31,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 19 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7172, Time: 0.312 seconds\n",
      "\n",
      "Batch size 128's Last Epoch - Mean Accuracy: 0.7207, Mean Time: 0.4051 seconds\n",
      "\n",
      "========== Starting with batch_size: 256 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:07<00:19,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7393, Time: 0.3703 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:09<00:16,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 39 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.7553, Time: 0.2324 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:08<00:17,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 34 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.7453, Time: 0.2238 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:06<00:19,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.7073, Time: 0.3654 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:07<00:18,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7463, Time: 0.2199 seconds\n",
      "\n",
      "Batch size 256's Last Epoch - Mean Accuracy: 0.7387, Mean Time: 0.2824 seconds\n",
      "\n",
      "========== Starting with batch_size: 512 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:05<00:14,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7002, Time: 0.1943 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:06<00:13,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.7305, Time: 0.1919 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:05<00:14,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.7073, Time: 0.1784 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:05<00:15,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 28 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.7073, Time: 0.2571 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:08<00:18,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7267, Time: 0.2576 seconds\n",
      "\n",
      "Batch size 512's Last Epoch - Mean Accuracy: 0.7144, Mean Time: 0.2159 seconds\n",
      "\n",
      "========== Starting with batch_size: 1024 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:08<00:15,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 36 during fold 1\n",
      "Fold 1 Last Epoch - Accuracy: 0.7257, Time: 0.1927 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:05<00:14,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30 during fold 2\n",
      "Fold 2 Last Epoch - Accuracy: 0.6949, Time: 0.2013 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:09<00:13,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 42 during fold 3\n",
      "Fold 3 Last Epoch - Accuracy: 0.7263, Time: 0.245 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:08<00:12,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 41 during fold 4\n",
      "Fold 4 Last Epoch - Accuracy: 0.7133, Time: 0.1645 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:06<00:12,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 37 during fold 5\n",
      "Fold 5 Last Epoch - Accuracy: 0.7244, Time: 0.166 seconds\n",
      "\n",
      "Batch size 1024's Last Epoch - Mean Accuracy: 0.7169, Mean Time: 0.1939 seconds\n",
      "\n",
      "Mean Cross-Validation Accuracy On Final Epoch Against Different Batch Sizes:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Mean Cross-Validation Accuracy On Final Epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.7207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.7169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Mean Cross-Validation Accuracy On Final Epoch\n",
       "0         128                                         0.7207\n",
       "1         256                                         0.7387\n",
       "2         512                                         0.7144\n",
       "3        1024                                         0.7169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, hyperparameter_name):\n",
    "    \n",
    "    # Initialize dictionaries to store results\n",
    "    cross_validation_accuracies = {size: [] for size in batch_sizes}\n",
    "    cross_validation_times = {size: [] for size in batch_sizes}\n",
    "    \n",
    "    # Define the loss function for training\n",
    "    loss_function = loss_fn\n",
    "    \n",
    "    # Get the number of input features from the first batch of the first fold\n",
    "    no_features = X_train_scaled_dict[batch_sizes[0]][0].shape[1]\n",
    "    \n",
    "    # Define the number of hidden units in the neural network\n",
    "    no_hidden = 128\n",
    "    \n",
    "    # Define the number of output labels (binary classification)\n",
    "    no_labels = 1\n",
    "    \n",
    "    # Define other hyperparameters\n",
    "    num_folds = 5\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Iterate through each batch size\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"========== Starting with {hyperparameter_name}: {batch_size} ==========\")\n",
    "        \n",
    "        # Iterate through each fold (5-fold cross-validation)\n",
    "        for i in range(num_folds):\n",
    "            \n",
    "            # Create a neural network model\n",
    "            model = MLP(no_features, no_hidden, no_labels)\n",
    "            \n",
    "            # Define the optimizer with a specified learning rate\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Get the training and validation data loaders for the current batch size and fold\n",
    "            train_loader = train_loaders_dict[batch_size][i]\n",
    "            val_loader = val_loaders_dict[batch_size][i]\n",
    "            \n",
    "            # Initialize an EarlyStopper object to monitor early stopping\n",
    "            early_stopper = EarlyStopper(patience=3)\n",
    "            \n",
    "            # Loop through the specified number of training epochs\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Train the model for one epoch and compute the training loss\n",
    "                train_loss = train_one_epoch(model, train_loader, optimizer, loss_function)\n",
    "                \n",
    "                # Evaluate the model on the validation set and compute accuracy AND loss\n",
    "                val_accuracy, val_loss = evaluate_model(model, val_loader, loss_function)\n",
    "                \n",
    "                # Calculate the time taken for this epoch\n",
    "                end_time = time.time()\n",
    "                last_epoch_time = end_time - start_time\n",
    "                \n",
    "                # Check for early stopping based on validation loss\n",
    "                if early_stopper.early_stop(val_loss):\n",
    "                    print(f\"Early stopping at epoch {epoch + 1} during fold {i + 1}\")\n",
    "                    break\n",
    "\n",
    "            \n",
    "            # Store the time taken for the last epoch for this fold\n",
    "            cross_validation_times[batch_size].append(last_epoch_time)\n",
    "            \n",
    "            # Store the validation accuracy for this fold\n",
    "            cross_validation_accuracies[batch_size].append(val_accuracy)\n",
    "            \n",
    "            # Print the results for this fold\n",
    "            print(f\"Fold {i + 1} Last Epoch - Accuracy: {round(val_accuracy,4)}, Time: {round(last_epoch_time,4)} seconds\")\n",
    "        \n",
    "        print()\n",
    "        # Calculate and print the mean cross-validation accuracy + mean time taken for last epoch for this batch size\n",
    "        mean_accuracy = sum(cross_validation_accuracies[batch_size]) / len(cross_validation_accuracies[batch_size])\n",
    "        mean_time = sum(cross_validation_times[batch_size]) / len(cross_validation_times[batch_size])\n",
    "        print(f\"Batch size {batch_size}'s Last Epoch - Mean Accuracy: {round(mean_accuracy,4)}, Mean Time: {round(mean_time,4)} seconds\")\n",
    "        print()\n",
    "        \n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')\n",
    "\n",
    "# Prepare for plotting\n",
    "batch_sizes_list = list(cross_validation_accuracies.keys())\n",
    "mean_cv_accuracies = [round(sum(cross_validation_accuracies[batch_size]) / len(cross_validation_accuracies[batch_size]),4) for batch_size in batch_sizes_list]\n",
    "\n",
    "# Create a dataframe for mean cross validation accuracies against batch sizes\n",
    "cv_accuracies_df = pd.DataFrame({\n",
    "    'Batch Size': batch_sizes_list,\n",
    "    'Mean Cross-Validation Accuracy On Final Epoch': mean_cv_accuracies\n",
    "})\n",
    "\n",
    "print(\"Mean Cross-Validation Accuracy On Final Epoch Against Different Batch Sizes:\")\n",
    "print()\n",
    "display(cv_accuracies_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791417a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAHHCAYAAABJDtd4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABu1ElEQVR4nO3dd1gUV/s38O8CUqQKSLOAHQuiQcEuKvaGFVCDYv3ZS6xJrHmMxthiNFYimqgoitH4PFERSdSIohg0WIgdFVARAQWl7Xn/8GXiupRdiiz6/VzXXMqZM2fuWWZ3b86cOSMTQggQERERUaG0yjoAIiIiovKCiRMRERGRipg4EREREamIiRMRERGRipg4EREREamIiRMRERGRipg4EREREamIiRMRERGRipg4EREREamIiRPR/3fv3j3IZDIEBARIZYsWLYJMJlNpe5lMhkWLFpVoTO7u7nB3dy/RNunjldc5XhocHBwwYsSIUt3H+yCTyTBp0qSyDqPc+P333yGTybB///5S31dZnmNMnFQUEBAAmUwGmUyGM2fOKK0XQqBatWqQyWTo1atXGUSonpycHGzfvh3u7u4wNzeHnp4eHBwc4Ofnh4sXL5Z1eIXq06cPKlasiBcvXuRbZ+jQodDV1cWzZ8/eY2Tqu3btGhYtWoR79+6VdSh5+t///geZTAY7OzvI5fKyDqfcefbsGWbNmoV69epBX18f5ubm6Nq1K44cOVLi+3r7c+rdZe7cuSW+v+LKL1aZTIb/+7//K+vwNFpukvL2Ym5ujhYtWmDXrl1FbveHH34o9cS6IH///TcGDhwIe3t76Ovro0qVKujcuTO+//77MovpXTplHUB5o6+vj927d6NNmzYK5X/88QcePnwIPT29MopMda9evUL//v1x9OhRtGvXDp9//jnMzc1x79497Nu3Dzt27EBsbCyqVq1a1qHma+jQofj1119x8OBB+Pr6Kq1PT0/HoUOH0K1bN1hYWBR5P19++WWpf+Fcu3YNixcvhru7OxwcHBTWHT9+vFT3rYpdu3bBwcEB9+7dw8mTJ+Hh4VHWIZUbMTEx6NSpE54+fQo/Pz80a9YMycnJ2LVrF3r37o2ZM2fi22+/LfH9LlmyBDVq1FAoa9SoEezt7fHq1StUqFChxPdZVJ07d87zPVy3bt0yiKb8mTJlCpo3bw7gTZK+d+9eDBs2DMnJyZg4caLa7f3www+wtLQsk96cs2fPokOHDqhevTrGjBkDGxsbPHjwAOfOncN3332HyZMnS3VjYmKgpVU2fT9MnNTUo0cPBAUFYd26ddDR+ffl2717N1xcXJCYmFiG0alm1qxZOHr0KNasWYNp06YprFu4cCHWrFlT4PZpaWkwNDQsxQgL16dPHxgbG2P37t15fugeOnQIaWlpGDp0aLH2o6Ojo/B7ft90dXXLbN/Am9/1oUOHsGzZMmzfvh27du3S2MRJE87Lt2VlZWHgwIF4/vw5Tp06BTc3N2nd9OnTMXToUKxcuRLNmjWDl5dXie67e/fuaNasWZ7r9PX1S3RfxVW3bl0MGzasrMMot9q2bYuBAwdKP48fPx41a9bE7t27i5Q4laWlS5fC1NQUFy5cgJmZmcK6J0+eKPxclp0UvFSnJh8fHzx79gwhISFSWWZmJvbv348hQ4bkuY1cLsfatWvRsGFD6Ovrw9raGuPGjcPz588V6h06dAg9e/aEnZ0d9PT0UKtWLXz11VfIyclRqOfu7o5GjRrh2rVr6NChAypWrIgqVapgxYoVhcb/8OFDbN68GZ07d1ZKmgBAW1sbM2fOlHqbcsf4XLt2DUOGDEGlSpWk3rbs7Gx89dVXqFWrlnSp7/PPP0dGRoZCmxcvXkTXrl1haWkJAwMD1KhRAyNHjlSoExgYCBcXFxgbG8PExAROTk747rvv8j0OAwMD9O/fH6GhoUpvKOBNImtsbIw+ffogKSkJM2fOhJOTE4yMjGBiYoLu3bvj8uXLhb5eeY1xysjIwPTp01G5cmVpHw8fPlTa9v79+5gwYQLq1asHAwMDWFhYYNCgQQqX5AICAjBo0CAAQIcOHaQu999//x1A3mOcnjx5glGjRsHa2hr6+vpwdnbGjh07FOrkjmVZuXIltmzZIv2OmjdvjgsXLhR63LkOHjyIV69eYdCgQfD29kZwcDBev36tVO/169dYtGgR6tatC319fdja2qJ///64ffu2VEcul+O7776Dk5MT9PX1UblyZXTr1k26NFzQ+Jt3x48VdF5euXIFI0aMQM2aNaGvrw8bGxuMHDkyz0u2jx49wqhRo6T3XI0aNTB+/HhkZmbizp07kMlkef4hcfbsWchkMuzZsyff1+7AgQOIjo7G3LlzFZIm4M37bPPmzTAzM1M4rtzLL/v27cPSpUtRtWpV6Ovro1OnTrh161a++1JVXq/xiBEjYGRkhEePHsHT0xNGRkaoXLkyZs6cqfTZs3LlSrRq1QoWFhYwMDCAi4vLexnPkvuZFxkZiVatWkmfI5s2bVKqq8r7Ayj8fHzbL7/8gkaNGkFPTw8NGzbE0aNHC4z38ePH0NHRweLFi5XWxcTEQCaTYf369QDeJNiLFy9GnTp1oK+vDwsLC7Rp00bhO0Ydurq6qFSpktIffNu3b0fHjh1hZWUFPT09NGjQABs3blSo4+DggKtXr+KPP/6QPove/vxJTk7G9OnT4eDgAD09PVStWhW+vr5KHQZyubxI5+/t27fRsGFDpaQJAKysrJRifbtXrKDLvm9/5t64cQMDBw6Eubk59PX10axZMxw+fLjQ2N7GHic1OTg4oGXLltizZw+6d+8OAPjtt9+QkpICb29vrFu3TmmbcePGISAgAH5+fpgyZQru3r2L9evX46+//sKff/4pdZsHBATAyMgIM2bMgJGREU6ePIkFCxYgNTVVqTv/+fPn6NatG/r374/Bgwdj//79mDNnDpycnKS48vLbb78hOzsbn376qVrHPWjQINSpUwdff/01hBAAgNGjR2PHjh0YOHAgPvvsM5w/fx7Lli3D9evXcfDgQQBvPsS6dOmCypUrY+7cuTAzM8O9e/cQHBwstR0SEgIfHx906tQJ33zzDQDg+vXr+PPPPzF16tR8Yxo6dCh27NiBffv2KQzgTEpKwrFjx+Dj4wMDAwNcvXoVv/zyCwYNGoQaNWrg8ePH2Lx5M9q3b49r167Bzs5Orddi9OjR+PnnnzFkyBC0atUKJ0+eRM+ePZXqXbhwAWfPnoW3tzeqVq2Ke/fuYePGjXB3d8e1a9dQsWJFtGvXDlOmTMG6devw+eefo379+gAg/fuuV69ewd3dHbdu3cKkSZNQo0YNBAUFYcSIEUhOTlZ6vXbv3o0XL15g3LhxkMlkWLFiBfr37487d+6odLlm165d6NChA2xsbODt7Y25c+fi119/lZI94M14uV69eiE0NBTe3t6YOnUqXrx4gZCQEERHR6NWrVoAgFGjRiEgIADdu3fH6NGjkZ2djdOnT+PcuXP59o4UJq/zMiQkBHfu3IGfnx9sbGxw9epVbNmyBVevXsW5c+ekRDguLg6urq5ITk7G2LFj4ejoiEePHmH//v1IT09HzZo10bp1a+zatQvTp09Xel2MjY3Rt2/ffGP79ddfASDPHlEAMDU1Rd++fbFjxw7cunULtWvXltYtX74cWlpamDlzJlJSUrBixQoMHToU58+fV+l1SUlJUfoys7S0zLd+Tk4OunbtCjc3N6xcuRInTpzAqlWrUKtWLYwfP16q991336FPnz4YOnQoMjMzERgYiEGDBuHIkSN5vgdU8fr16zx76k1MTBR6XJ8/f44ePXpg8ODB8PHxwb59+zB+/Hjo6upKf4ip8/5Q9Xw8c+YMgoODMWHCBBgbG2PdunUYMGAAYmNj8x0GYG1tjfbt22Pfvn1YuHChwrq9e/dCW1tbeg8tWrQIy5Ytw+jRo+Hq6orU1FRcvHgRly5dQufOnQt9/V68eCG9fklJSdi9ezeio6Ph7++vUG/jxo1o2LAh+vTpAx0dHfz666+YMGEC5HK51DO1du1aTJ48GUZGRvjiiy+kYwGAly9fom3btrh+/TpGjhyJTz75BImJiTh8+DAePnyocH4V9fy1t7dHeHg4oqOj0ahRo0KP/W0//fSTUtmXX36JJ0+ewMjICABw9epVtG7dGlWqVMHcuXNhaGiIffv2wdPTEwcOHEC/fv1U25kglWzfvl0AEBcuXBDr168XxsbGIj09XQghxKBBg0SHDh2EEELY29uLnj17StudPn1aABC7du1SaO/o0aNK5bntvW3cuHGiYsWK4vXr11JZ+/btBQCxc+dOqSwjI0PY2NiIAQMGFHgc06dPFwDEX3/9pdJxL1y4UAAQPj4+CuVRUVECgBg9erRC+cyZMwUAcfLkSSGEEAcPHpRet/xMnTpVmJiYiOzsbJViypWdnS1sbW1Fy5YtFco3bdokAIhjx44JIYR4/fq1yMnJUahz9+5doaenJ5YsWaJQBkBs375dKss9/nePe8KECQrtDRkyRAAQCxculMry+n2Gh4cr/e6CgoIEABEWFqZUv3379qJ9+/bSz2vXrhUAxM8//yyVZWZmipYtWwojIyORmpqqcCwWFhYiKSlJqnvo0CEBQPz6669K+3rX48ePhY6Ojti6datU1qpVK9G3b1+Fej/++KMAIFavXq3UhlwuF0IIcfLkSQFATJkyJd86eb3+ud59bfM7L4XI+3Xfs2ePACBOnTollfn6+gotLa08z83cmDZv3iwAiOvXr0vrMjMzhaWlpRg+fLjSdm9r0qSJMDU1LbDO6tWrBQBx+PBhIYQQYWFhAoCoX7++yMjIkOp99913AoD4+++/C2wv93Mqr0WIvF/j4cOHCwAK7wUhhGjatKlwcXFRKHv3tc3MzBSNGjUSHTt2VCi3t7cv9PURQuQbKwCxZ88eqV7uZ96qVauksoyMDNGkSRNhZWUlMjMzhRCqvz9UOR9z49PV1RW3bt2Syi5fviwAiO+//77AY8s9d979nTVo0EDh9XJ2dlb4zlBV7rny7qKlpSWWLl2qVD+v90XXrl1FzZo1FcoaNmyo8JmTa8GCBQKACA4OVlqX+5oV9/w9fvy40NbWFtra2qJly5Zi9uzZ4tixY9Lv922FnWMrVqxQ+qzt1KmTcHJyUvg+lcvlolWrVqJOnToFxvY2XqorgsGDB+PVq1c4cuQIXrx4gSNHjuR7mS4oKAimpqbo3LkzEhMTpcXFxQVGRkYICwuT6hoYGEj/z/0rom3btkhPT8eNGzcU2jUyMlIYF6CrqwtXV1fcuXOnwNhTU1MBAMbGxmod87t3uPzvf/8DAMyYMUOh/LPPPgMA/Pe//wUAqcv1yJEjyMrKyrNtMzMzpKWlqd01ra2tDW9vb4SHhyt0xe7evRvW1tbo1KkTgDfXwnMHEebk5ODZs2cwMjJCvXr1cOnSJbX2mXvcU6ZMUSjP67Ln27/PrKwsPHv2DLVr14aZmZna+317/zY2NvDx8ZHKKlSogClTpuDly5f4448/FOp7eXmhUqVK0s9t27YFgELPE+DN5VMtLS0MGDBAKvPx8cFvv/2mcJn5wIEDsLS0VBi4mSu3d+fAgQOQyWRKf32/Xaco8rrz6u3XPbc3o0WLFgAgve5yuRy//PILevfunWdvV25MgwcPhr6+vsJdSseOHUNiYmKh43JevHhR6Pssd33u+zKXn5+fQm+LOr83ANiwYQNCQkIUlsK8+1q2bdtWaX9vv7bPnz9HSkoK2rZtW+TzGQD69u2rFGtISAg6dOigUE9HRwfjxo2TftbV1cW4cePw5MkTREZGAlD9/aHO+ejh4SH1mgJA48aNYWJiUujvon///tDR0cHevXulsujoaFy7dk1hTJuZmRmuXr2KmzdvFthefhYsWCC9Znv37oWPjw+++OILpaEOb//ucnsk27dvjzt37iAlJaXQ/Rw4cADOzs559sq8+5oV9fzt3LkzwsPD0adPH1y+fBkrVqxA165dUaVKFbUup4WFhWHevHmYPHmydHUlKSkJJ0+exODBg6Xv18TERDx79gxdu3bFzZs38ejRI5XaZ+JUBJUrV4aHhwd2796N4OBg5OTkKAzOe9vNmzeRkpICKysrVK5cWWF5+fKlwvicq1evol+/fjA1NYWJiQkqV64sfTi/e2JXrVpV6WStVKmS0ripd5mYmABAgbfx5+XdO3Tu378PLS0thcsLAGBjYwMzMzPcv38fANC+fXsMGDAAixcvhqWlJfr27Yvt27crjIOaMGEC6tati+7du6Nq1aoYOXKkwhiCnJwcJCQkKCyZmZkAIA3+3r17N4A3Y7hOnz4Nb29vaGtrA3jzJblmzRrUqVMHenp6sLS0ROXKlXHlyhWVPjDyOu63P0gBoF69ekp1X716hQULFqBatWoK+01OTlZ7v2/vv06dOkp3k+Re2st93XNVr15d4efcJKqw8wQAfv75Z7i6uuLZs2e4desWbt26haZNmyIzMxNBQUFSvdu3b6NevXoFDqK/ffs27OzsYG5uXuh+1fHueQm8+YCcOnUqrK2tYWBggMqVK0v1cl/3p0+fIjU1tdDLAWZmZujdu7d0fgFvLtNVqVIFHTt2LHBbY2PjQt9nuevfTbCK83sDAFdXV3h4eCgsBckd4/PuPt/d35EjR9CiRQtpWoXKlStj48aNRT6fgTefZe/G6uHhIV0iymVnZ6c0+D/3zrvcP5xUfX+ocz6++7sAVPustbS0RKdOnbBv3z6pbO/evdDR0UH//v2lsiVLliA5ORl169aFk5MTZs2ahStXrhQaVy4nJyfpNRs8eDB+/vln9OrVC3PnzsXTp0+len/++Sc8PDxgaGgIMzMzVK5cGZ9//jkA5e+XvNy+fVvly2fFOX+bN2+O4OBgPH/+HBEREZg3bx5evHiBgQMH4tq1a4Vu//DhQ3h5eaF169ZYvXq1VH7r1i0IITB//nyl7+LcBDqv8bJ54RinIhoyZAjGjBmDhIQEdO/ePc/BbMCbL20rK6t859XI/bBKTk5G+/btYWJigiVLlqBWrVrQ19fHpUuXMGfOHKX5c3KTgneJ/z/OIz+Ojo4A3syV0aRJkwLrvu3tv1beVlhvQe5kaOfOncOvv/6KY8eOYeTIkVi1ahXOnTsHIyMjWFlZISoqCseOHcNvv/2G3377Ddu3b4evry927NiBBw8eKH1BhoWFwd3dHS4uLnB0dMSePXvw+eefY8+ePRBCKNxN9/XXX2P+/PkYOXIkvvrqK5ibm0NLSwvTpk0r1XmJJk+ejO3bt2PatGlo2bIlTE1NIZPJ4O3t/d7mQyrqeXLz5k1pEHmdOnWU1u/atQtjx44tfoBvye9ceneA8tvyOi8HDx6Ms2fPYtasWWjSpAmMjIwgl8vRrVu3Ir3uvr6+CAoKwtmzZ+Hk5ITDhw9jwoQJhd4KXb9+fURFRSE2NjbPL18A0hdkgwYNFMqL+nsrqvz297bTp0+jT58+aNeuHX744QfY2tqiQoUK2L59u0Ji+aEpzu/C29sbfn5+iIqKQpMmTbBv3z506tRJYTxQu3btcPv2bRw6dAjHjx/Htm3bsGbNGmzatAmjR48uUsydOnXCkSNHEBERgZ49e+L27dvo1KkTHB0dsXr1alSrVg26urr43//+hzVr1pT451FJnL+6urpo3rw5mjdvjrp168LPzw9BQUF59hLmyszMxMCBA6Gnp4d9+/Yp/DGXe4wzZ85E165d89z+3Y6A/DBxKqJ+/fph3LhxOHfunEJX7Ltq1aqFEydOoHXr1vkmH8Cbu2mePXuG4OBgtGvXTiq/e/duicbdvXt3aGtr4+eff1Z7gPjb7O3tIZfLcfPmTYWBzI8fP0ZycjLs7e0V6rdo0QItWrTA0qVLsXv3bgwdOhSBgYHSB4Ouri569+6N3r17Qy6XY8KECdi8eTPmz5+PqlWrKl1qcHZ2lv4/dOhQzJ8/H1euXMHu3btRp04daV4TANi/fz86dOigNFgyOTm5wAGzBR13bi9LrpiYGKW6+/fvx/Dhw7Fq1Sqp7PXr10hOTlaop86lKnt7e1y5cgVyuVzhizv3Uu67r3tR7dq1CxUqVMBPP/2k9CF45swZrFu3TkoIatWqhfPnzyMrKyvfAee1atXCsWPHkJSUlO9f+bl/lb77+rzbi1aQ58+fIzQ0FIsXL8aCBQuk8ncvg1SuXBkmJiaIjo4utM1u3bqhcuXK2LVrF9zc3JCenq7Se6dXr17Ys2cPdu7ciS+//FJpfWpqKg4dOgRHR0eVP7DL0oEDB6Cvr49jx44p3Aq+ffv297L/uLg4pSkn/vnnHwCQ5j9T9f2hyvlYEjw9PTFu3DjpO+Kff/7BvHnzlOqZm5vDz88Pfn5+ePnyJdq1a4dFixYVOXHKzs4G8GZAN/DmRoWMjAwcPnxYIYl/e6hIrvw+j2rVqqXS+6U05F5Oj4+PL7DelClTEBUVhVOnTin1WNasWRPAm0u3xZ1ShZfqisjIyAgbN27EokWL0Lt373zrDR48GDk5Ofjqq6+U1mVnZ0tfErlfTm9n5JmZmfjhhx9KNO5q1aphzJgxOH78eJ4zscrlcqxatSrP2+vf1qNHDwBv7sJ4W27XaO4dNs+fP1f6KyO3pyv3ct27t4lraWmhcePGUh19fX2lbvy3x+3k9i4tWLAAUVFRSnM3aWtrK8UQFBSk8vXst+Xesfju3ZPvvg757ff7779X6kHJ/SJ4N2HIS48ePZCQkKCQrGdnZ+P777+HkZER2rdvr8phFGrXrl1o27YtvLy8MHDgQIVl1qxZACDdij9gwAAkJiZKt1e/Lff4BwwYACFEnrdn59YxMTGBpaUlTp06pbBenfdAXu8jQPn3o6WlBU9PT/z666953n7+9vY6OjrSXVwBAQFwcnKSzs+CDBw4EA0aNMDy5cuV9iGXyzF+/Hg8f/68wL+gNYm2tjZkMpnC+Xvv3j388ssv72X/2dnZ2Lx5s/RzZmYmNm/ejMqVK8PFxQWA6u8PVc7HkmBmZoauXbti3759CAwMhK6uLjw9PRXqvPv5Z2RkhNq1aytN66KO3Fnpc//AzOt9kZKSkmfSa2homOdn0YABA3D58mXpjum3ldRrFhYWlmdbuWNL8xoSkWv79u3YvHkzNmzYAFdXV6X1VlZWcHd3x+bNm/NMwN6+rFkY9jgVw/Dhwwut0759e4wbNw7Lli1DVFQUunTpggoVKuDmzZsICgrCd999h4EDB6JVq1aoVKkShg8fjilTpkAmk+Gnn34qla75VatW4fbt25gyZQqCg4PRq1cvVKpUCbGxsQgKCsKNGzfg7e1dYBvOzs4YPnw4tmzZIl1mjIiIwI4dO+Dp6SkN7NyxYwd++OEH9OvXD7Vq1cKLFy+wdetWmJiYSMnX6NGjkZSUhI4dO6Jq1aq4f/8+vv/+ezRp0iTf2/LfVqNGDbRq1QqHDh0CAKXEqVevXliyZAn8/PzQqlUr/P3339i1a5f0F4g6mjRpAh8fH/zwww9ISUlBq1atEBoamuccJb169cJPP/0EU1NTNGjQAOHh4Thx4oTSLcxNmjSBtrY2vvnmG6SkpEBPT0+ab+VdY8eOxebNmzFixAhERkbCwcEB+/fvx59//om1a9eqPeg/L+fPn5du585LlSpV8Mknn2DXrl2YM2cOfH19sXPnTsyYMQMRERFo27Yt0tLScOLECUyYMAF9+/ZFhw4d8Omnn2LdunW4efOmdNns9OnT6NChg7Sv0aNHY/ny5Rg9ejSaNWuGU6dOSb0KqjAxMUG7du2wYsUKZGVloUqVKjh+/HiePbdff/01jh8/jvbt22Ps2LGoX78+4uPjERQUhDNnzihcfvf19cW6desQFhYmTZlRGF1dXezfvx+dOnVCmzZtFGYO3717Ny5duoTPPvus0PeapujZsydWr16Nbt26YciQIXjy5Ak2bNiA2rVrqzUm513//PMPfv75Z6Vya2trhdvx7ezs8M033+DevXuoW7cu9u7di6ioKGzZskXq6VT1/aHq+VgSvLy8MGzYMPzwww/o2rWr0rCOBg0aSMMOzM3NcfHiRezfv1/lGE6fPi3NrZaUlITDhw/jjz/+gLe3tzQ0o0uXLlKv/rhx4/Dy5Uts3boVVlZWSkmEi4sLNm7ciP/85z+oXbs2rKys0LFjR8yaNQv79+/HoEGDMHLkSLi4uEj727Rpk8JVgKKaPHky0tPT0a9fPzg6OiIzMxNnz57F3r17pUeC5SUxMRETJkxAgwYNoKenp3Q+9evXD4aGhtiwYQPatGkDJycnjBkzBjVr1sTjx48RHh6Ohw8fqjS3HwBOR6Cqt6cjKMi70xHk2rJli3BxcREGBgbC2NhYODk5idmzZ4u4uDipzp9//ilatGghDAwMhJ2dnXQrJt65Vb19+/aiYcOGSvsYPny4sLe3V+l4srOzxbZt20Tbtm2FqampqFChgrC3txd+fn4KUxXk3vb99OlTpTaysrLE4sWLRY0aNUSFChVEtWrVxLx58xRu9bx06ZLw8fER1atXF3p6esLKykr06tVLXLx4Uaqzf/9+0aVLF2FlZSV0dXVF9erVxbhx40R8fLxKxyKEEBs2bBAAhKurq9K6169fi88++0zY2toKAwMD0bp1axEeHq50q78q0xEIIcSrV6/ElClThIWFhTA0NBS9e/cWDx48ULpl/vnz58LPz09YWloKIyMj0bVrV3Hjxo08b6PdunWrqFmzptDW1lb4fb8boxBvpgnIbVdXV1c4OTkp3cKfeyzffvut0uvxbpzvmjx5sgAgbt++nW+dRYsWCQDi8uXLQog3tzp/8cUX0rlgY2MjBg4cqNBGdna2+Pbbb4Wjo6PQ1dUVlStXFt27dxeRkZFSnfT0dDFq1ChhamoqjI2NxeDBg8WTJ0/ynY4gr/Py4cOHol+/fsLMzEyYmpqKQYMGibi4uDyP+/79+8LX11dUrlxZ6OnpiZo1a4qJEycq3Eqdq2HDhkJLS0s8fPgw39clL0+ePBEzZswQtWvXFnp6esLMzEx4eHhIUxC8Lfd27qCgIIXygqZqeFthn1P5TUdgaGioVDevc9/f31/UqVNH6OnpCUdHR7F9+/Y865XEdARvn/e5n3kXL14ULVu2FPr6+sLe3l6sX79eqU1V3h9CqHY+AhATJ05U2lbV4xNCiNTUVGFgYKA0TUKu//znP8LV1VWYmZkJAwMD4ejoKJYuXZrnLfhvy2s6Al1d3Xy3P3z4sGjcuLHQ19cXDg4O4ptvvpGmErl7965ULyEhQfTs2VMYGxsr/R6ePXsmJk2aJKpUqSJ0dXVF1apVxfDhw0ViYqJCTEU9f3/77TcxcuRI4ejoKIyMjISurq6oXbu2mDx5snj8+LFC3bd/B7nt57e8fXy3b98Wvr6+wsbGRlSoUEFUqVJF9OrVS+zfv7/A2N4mE6KURhsSEX1AmjZtCnNzc4SGhpZ1KB8dd3d3JCYmltkYG6K3cYwTEVEhLl68iKioqHxnASeijwfHOBER5SM6OhqRkZFYtWoVbG1tS/xhvERU/rDHiYgoH/v374efnx+ysrKwZ88e6Ovrl3VIRFTGOMaJiIiISEXscSIiIiJSERMnIiIiIhVxcHgRyeVyxMXFwdjYuFhPdyciIqL3RwiBFy9ewM7OrtBnTuaFiVMRxcXFoVq1amUdBhERERXBgwcPULVqVbW3Y+JURLlT9z948AAmJiZlHA0RERGpIjU1FdWqVSvyI6qYOBVR7uU5ExMTJk5ERETlTFGH2XBwOBEREZGKmDgRERERqYiJExEREZGKmDgRERERqYiJExEREZGKmDgRERERqYiJExEREZGKmDgRERERqYiJExEREZGKmDiRRkh9nYX4lFd5rotPeYXU11nvOSIiIiJlTJyozKW+zsLwHyPgtfkc4pIVk6e45Ffw2nwOw3+MYPJERERljokTlbm0jGw8e5mJ2KR0eG/5N3mKS34F7y3nEJuUjmcvM5GWkV3GkRIR0ceOiROVOVtTAwSObYHq5hWl5CnyfpKUNFU3r4jAsS1ga2pQ1qESEdFHTiaEEGUdRHmUmpoKU1NTpKSkwMTEpKzD+SC83cOUKzdpsjNj0kRERMVX3O9v9jiRxrAzM8AaL2eFsjVezkyaiIhIYzBxIo0Rl/wK0/deViibvvey0oBxIiKissLEiTTC25fpqptXxIHxLRXGPDF5IiIiTcDEicpcfMorpYHgLvbmSgPG85vniYiI6H1h4kRlzlBPBxZGukoDwe3M/r3bzsJIF4Z6OmUcKRERfex4V10R8a66kpX6OgtpGdl5TjkQn/IKhno6MNGvUAaRERHRh6S439/8E540gol+hXwTI87fREREmoKX6qhUbNiwAQ4ODtDX14ebmxsiIiLyrevu7g6ZTKa09OzZU6qzaNEiODo6wtDQEJUqVYKHhwfOnz+v0M4///yDvn37wtLSEiYmJmjTpg3CwsKk9QEBAXnuRyaT4cmTJyX/IhAR0QeHiROVuL1792LGjBlYuHAhLl26BGdnZ3Tt2jXf5CQ4OBjx8fHSEh0dDW1tbQwaNEiqU7duXaxfvx5///03zpw5AwcHB3Tp0gVPnz6V6vTq1QvZ2dk4efIkIiMj4ezsjF69eiEhIQEA4OXlpbCf+Ph4dO3aFe3bt4eVlVXpvihERPRB4BinIuIYp/y5ubmhefPmWL9+PQBALpejWrVqmDx5MubOnVvo9mvXrsWCBQsQHx8PQ0PDPOvkvv4nTpxAp06dkJiYiMqVK+PUqVNo27YtAODFixcwMTFBSEgIPDw8lNp4+vQpqlSpAn9/f3z66afFOGIiIiovOHM4aZTMzExERkYqJCpaWlrw8PBAeHi4Sm34+/vD29s736QpMzMTW7ZsgampKZyd38w0bmFhgXr16mHnzp1IS0tDdnY2Nm/eDCsrK7i4uOTZzs6dO1GxYkUMHDhQzaMkIqKPFQeHU4lKTExETk4OrK2tFcqtra1x48aNQrePiIhAdHQ0/P39ldYdOXIE3t7eSE9Ph62tLUJCQmBpaQkAkMlkOHHiBDw9PWFsbAwtLS1YWVnh6NGjqFSpUp778vf3x5AhQ2BgwMHnRESkGvY4kUbx9/eHk5MTXF1dldZ16NABUVFROHv2LLp164bBgwdL46aEEJg4cSKsrKxw+vRpREREwNPTE71790Z8fLxSW+Hh4bh+/TpGjRpV6sdEREQfDiZOVKIsLS2hra2Nx48fK5Q/fvwYNjY2BW6blpaGwMDAfJMZQ0ND1K5dGy1atIC/vz90dHSknqmTJ0/iyJEjCAwMROvWrfHJJ5/ghx9+gIGBAXbs2KHU1rZt29CkSZN8L+MRERHlhYkTlShdXV24uLggNDRUKpPL5QgNDUXLli0L3DYoKAgZGRkYNmyYSvuSy+XIyMgAAKSnpwN4M57qbVpaWpDL5QplL1++xL59+9jbREREamPiRCVuxowZ2Lp1K3bs2IHr169j/PjxSEtLg5+fHwDA19cX8+bNU9rO398fnp6esLCwUChPS0vD559/jnPnzuH+/fuIjIzEyJEj8ejRI2nKgpYtW6JSpUoYPnw4Ll++jH/++QezZs3C3bt3FeaDAt5Ml5Cdna1ygkZERJSLg8OpxHl5eeHp06dYsGABEhIS0KRJExw9elQaMB4bG6vUMxQTE4MzZ87g+PHjSu1pa2vjxo0b2LFjBxITE2FhYYHmzZvj9OnTaNiwIYA3lwiPHj2KL774Ah07dkRWVhYaNmyIQ4cOSXfe5fL390f//v1hZmZWOi8AERF9sDiPUxFxHiciIqLyh/M4EREREb0nTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFTJyIiIiIVMTEiYiIiEhFGpE4bdiwAQ4ODtDX14ebmxsiIiLyrevu7g6ZTKa09OzZU6qzaNEiODo6wtDQEJUqVYKHhwfOnz+v0I6Dg4NSG8uXLy+1YyQiIqLyr8wTp71792LGjBlYuHAhLl26BGdnZ3Tt2hVPnjzJs35wcDDi4+OlJTo6Gtra2hg0aJBUp27duli/fj3+/vtvnDlzBg4ODujSpQuePn2q0NaSJUsU2po8eXKpHisRERGVbzIhhCjLANzc3NC8eXOsX78eACCXy1GtWjVMnjwZc+fOLXT7tWvXYsGCBYiPj4ehoWGedVJTU2FqaooTJ06gU6dOAN70OE2bNg3Tpk0rUty5baakpMDExKRIbRAREdH7Vdzv7zLtccrMzERkZCQ8PDykMi0tLXh4eCA8PFylNvz9/eHt7Z1v0pSZmYktW7bA1NQUzs7OCuuWL18OCwsLNG3aFN9++y2ys7Pz3U9GRgZSU1MVFiIiIvq46JTlzhMTE5GTkwNra2uFcmtra9y4caPQ7SMiIhAdHQ1/f3+ldUeOHIG3tzfS09Nha2uLkJAQWFpaSuunTJmCTz75BObm5jh79izmzZuH+Ph4rF69Os99LVu2DIsXL1bzCImIiOhDUqaJU3H5+/vDyckJrq6uSus6dOiAqKgoJCYmYuvWrRg8eDDOnz8PKysrAMCMGTOkuo0bN4auri7GjRuHZcuWQU9PT6m9efPmKWyTmpqKatWqlcJRERERkaYq00t1lpaW0NbWxuPHjxXKHz9+DBsbmwK3TUtLQ2BgIEaNGpXnekNDQ9SuXRstWrSAv78/dHR08uyZyuXm5obs7Gzcu3cvz/V6enowMTFRWIiIiOjjUqaJk66uLlxcXBAaGiqVyeVyhIaGomXLlgVuGxQUhIyMDAwbNkylfcnlcmRkZOS7PioqClpaWlKPFBEREdG7yvxS3YwZMzB8+HA0a9YMrq6uWLt2LdLS0uDn5wcA8PX1RZUqVbBs2TKF7fz9/eHp6QkLCwuF8rS0NCxduhR9+vSBra0tEhMTsWHDBjx69EiasiA8PBznz59Hhw4dYGxsjPDwcEyfPh3Dhg1DpUqV3s+BExERUblT5omTl5cXnj59igULFiAhIQFNmjTB0aNHpQHjsbGx0NJS7BiLiYnBmTNncPz4caX2tLW1cePGDezYsQOJiYmwsLBA8+bNcfr0aTRs2BDAm8tugYGBWLRoETIyMlCjRg1Mnz5dYQwTERER0bvKfB6n8orzOBEREZU/5XoeJyIiIqLyRO3EaeHChbh//35pxEJERESk0dROnA4dOoRatWqhU6dO2L17d4F3qhERERF9SNROnKKionDhwgU0bNgQU6dOhY2NDcaPH48LFy6URnxEREREGqNIY5yaNm2KdevWIS4uDv7+/nj48CFat26Nxo0b47vvvkNKSkpJx0lERERU5oo1OFwIgaysLGRmZkIIgUqVKmH9+vWoVq0a9u7dW1IxEhEREWmEIiVOkZGRmDRpEmxtbTF9+nQ0bdoU169fxx9//IGbN29i6dKlmDJlSknHSkRERFSm1J7HycnJCTdu3ECXLl0wZswY9O7dG9ra2gp1EhMTYWVlBblcXqLBahLO40RERFT+FPf7W+2ZwwcPHoyRI0eiSpUq+daxtLT8oJMmIiIi+jhx5vAiYo8TERFR+fPeZw4fMGAAvvnmG6XyFStWSA/RJSIiIvoQqZ04nTp1Cj169FAq7969O06dOlUiQRERERFpIrUTp5cvX0JXV1epvEKFCkhNTS2RoIiIiIg0kdqJk5OTU55zNAUGBqJBgwYlEhQRERGRJlL7rrr58+ejf//+uH37Njp27AgACA0NxZ49exAUFFTiARIRERFpCrUTp969e+OXX37B119/jf3798PAwACNGzfGiRMn0L59+9KIkYiIiEgjcDqCIuJ0BEREROXPe5+OgIiIiOhjpfalupycHKxZswb79u1DbGwsMjMzFdYnJSWVWHBEREREmkTtHqfFixdj9erV8PLyQkpKCmbMmIH+/ftDS0sLixYtKoUQiYiIiDSD2onTrl27sHXrVnz22WfQ0dGBj48Ptm3bhgULFuDcuXOlESMRERGRRlA7cUpISICTkxMAwMjICCkpKQCAXr164b///W/JRkdERESkQdROnKpWrYr4+HgAQK1atXD8+HEAwIULF6Cnp1ey0RERERFpELUTp379+iE0NBQAMHnyZMyfPx916tSBr68vRo4cWeIBEhEREWmKYs/jdO7cOZw9exZ16tRB7969Syoujcd5nIiIiMqf4n5/qzUdQVZWFsaNG4f58+ejRo0aAIAWLVqgRYsWau+YiIiIqLxR61JdhQoVcODAgdKKhYiIiEijqT3GydPTE7/88ksphEJERESk2dSeObxOnTpYsmQJ/vzzT7i4uMDQ0FBh/ZQpU0osOCIiIiJNovbg8NyxTXk2JpPhzp07xQ6qPODgcCIiovLnvQ4OB4C7d++qvRMiIiKiD4HaY5yIiIiIPlZq9zgVNsnljz/+WORgiIiIiDSZ2onT8+fPFX7OyspCdHQ0kpOT0bFjxxILjIiIiEjTqJ04HTx4UKlMLpdj/PjxqFWrVokERURERKSJSmSMk5aWFmbMmIE1a9aURHNEREREGqnEBoffvn0b2dnZJdUcERERkcZR+1LdjBkzFH4WQiA+Ph7//e9/MXz48BILjIiIiEjTqJ04/fXXXwo/a2lpoXLlyli1alWhd9wRERERlWdqJ05hYWGlEQcRERGRxlN7jNPdu3dx8+ZNpfKbN2/i3r17JRETERERkUZSO3EaMWIEzp49q1R+/vx5jBgxoiRiIiIiItJIaidOf/31F1q3bq1U3qJFC0RFRZVETEREREQaSe3ESSaT4cWLF0rlKSkpyMnJKZGgiIiIiDSR2olTu3btsGzZMoUkKScnB8uWLUObNm1KNDgiIiIiTaL2XXXffPMN2rVrh3r16qFt27YAgNOnTyM1NRUnT54s8QCJiIiINIXaPU4NGjTAlStXMHjwYDx58gQvXryAr68vbty4gUaNGpVGjEREREQaQSaEEGUdRHmUmpoKU1NTpKSkwMTEpKzDISIiIhUU9/tb7R6n7du3IygoSKk8KCgIO3bsUDsAIiIiovJC7cRp2bJlsLS0VCq3srLC119/XSJBEREREWkitROn2NhY1KhRQ6nc3t4esbGxJRIUERERkSZSO3GysrLClStXlMovX74MCwuLEgmKiIiISBOpnTj5+PhgypQpCAsLQ05ODnJycnDy5ElMnToV3t7epREjERERkUZQex6nr776Cvfu3UOnTp2go/Nmc7lcDl9fXyxdurTEAyQiIiLSFEWejuDmzZuIioqCgYEBnJycYG9vX9KxaTROR0BERFT+FPf7W+0ep1x16tRBnTp1pCA2btwIf39/XLx4sahNEhEREWm0IidOABAWFoYff/wRwcHBMDU1Rb9+/UoqLiIiIiKNo3bi9OjRIwQEBGD79u1ITk7G8+fPsXv3bgwePBgymaw0YiQiIiLSCCrfVXfgwAH06NED9erVQ1RUFFatWoW4uDhoaWnBycmpWEnThg0b4ODgAH19fbi5uSEiIiLfuu7u7pDJZEpLz549pTqLFi2Co6MjDA0NUalSJXh4eOD8+fMK7SQlJWHo0KEwMTGBmZkZRo0ahZcvXxb5GIiIiOjDp3Li5OXlhaZNmyI+Ph5BQUHo27cvdHV1ix3A3r17MWPGDCxcuBCXLl2Cs7MzunbtiidPnuRZPzg4GPHx8dISHR0NbW1tDBo0SKpTt25drF+/Hn///TfOnDkDBwcHdOnSBU+fPpXqDB06FFevXkVISAiOHDmCU6dOYezYscU+HiIiIvqACRWNHTtWmJqailatWomNGzeKpKQkIYQQOjo64urVq6o2o8TV1VVMnDhR+jknJ0fY2dmJZcuWqbT9mjVrhLGxsXj58mW+dVJSUgQAceLECSGEENeuXRMAxIULF6Q6v/32m5DJZOLRo0cq7Te3zZSUFJXqExERUdkr7ve3yj1OmzdvRnx8PMaOHYs9e/bA1tYWffv2hRACcrm8SElbZmYmIiMj4eHhIZVpaWnBw8MD4eHhKrXh7+8Pb29vGBoa5ruPLVu2wNTUFM7OzgCA8PBwmJmZoVmzZlI9Dw8PaGlpKV3Sy5WRkYHU1FSFhYiIiD4uas0cbmBggOHDh+OPP/7A33//jYYNG8La2hqtW7fGkCFDEBwcrNbOExMTkZOTA2tra4Vya2trJCQkFLp9REQEoqOjMXr0aKV1R44cgZGREfT19bFmzRqEhIRIDydOSEiAlZWVQn0dHR2Ym5vnu99ly5bB1NRUWqpVq6bqYRIREdEHQu1HruSqU6cOvv76azx48AA///wz0tPT4ePjU5KxFcrf3x9OTk5wdXVVWtehQwdERUXh7Nmz6NatGwYPHpzvuClVzJs3DykpKdLy4MGD4oRORERE5VCREyepAS0t9O7dG7/88ovayYSlpSW0tbXx+PFjhfLHjx/DxsamwG3T0tIQGBiIUaNG5bne0NAQtWvXRosWLeDv7w8dHR34+/sDAGxsbJSSqOzsbCQlJeW7Xz09PZiYmCgsRERE9HEpduL0tncvfxVGV1cXLi4uCA0NlcrkcjlCQ0PRsmXLArcNCgpCRkYGhg0bptK+5HI5MjIyAAAtW7ZEcnIyIiMjpfUnT56EXC6Hm5ubWsdAREREH49izRxeEmbMmIHhw4ejWbNmcHV1xdq1a5GWlgY/Pz8AgK+vL6pUqYJly5YpbOfv7w9PT09YWFgolKelpWHp0qXo06cPbG1tkZiYiA0bNuDRo0fSlAX169dHt27dMGbMGGzatAlZWVmYNGkSvL29YWdn934OnIiIiMqdMk+cvLy88PTpUyxYsAAJCQlo0qQJjh49Kg0Yj42NhZaWYsdYTEwMzpw5g+PHjyu1p62tjRs3bmDHjh1ITEyEhYUFmjdvjtOnT6Nhw4ZSvV27dmHSpEno1KkTtLS0MGDAAKxbt650D5aIiIjKNZkQQpR1EOVRcZ+uTERERO9fcb+/i9zjlJmZiSdPnijN4VS9evWiNklERESk0dROnG7evImRI0fi7NmzCuVCCMhkMuTk5JRYcERERESaRO3EacSIEdDR0cGRI0dga2tbrIf7EhEREZUnaidOUVFRiIyMhKOjY2nEQ0RERKSx1J7HqUGDBkhMTCyNWIiIiIg0mtqJ0zfffIPZs2fj999/x7Nnz/jgWyIiIvpoqD0dQe6cSu+ObfrYBodzOgIiIqLy571PRxAWFqb2ToiIiIg+BGonTu3bty+NOIiIiIg0XpEmwExOToa/vz+uX78OAGjYsCFGjhwJU1PTEg2OiIiISJOoPTj84sWLqFWrFtasWYOkpCQkJSVh9erVqFWrFi5dulQaMRIRERFpBLUHh7dt2xa1a9fG1q1boaPzpsMqOzsbo0ePxp07d3Dq1KlSCVTTcHA4ERFR+VPc72+1EycDAwP89ddfShNgXrt2Dc2aNUN6erraQZRHTJyIiIjKn+J+f6t9qc7ExASxsbFK5Q8ePICxsbHaARARERGVF2onTl5eXhg1ahT27t2LBw8e4MGDBwgMDMTo0aPh4+NTGjESERERaQS176pbuXIlZDIZfH19kZ2dDQCoUKECxo8fj+XLl5d4gERERESaQu0xTrnS09Nx+/ZtAECtWrVQsWLFEg1M03GMExERUfnz3mcOz1WxYkU4OTkVdXMiIiKickelxKl///4ICAiAiYkJ+vfvX2Dd4ODgEgmMiIiISNOolDiZmppKD/U1MTFResAvERER0cegyGOcPnYc40RERFT+vPd5nDp27Ijk5OQ8A+nYsaPaARARERGVF2onTr///jsyMzOVyl+/fo3Tp0+XSFBEREREmkjlu+quXLki/f/atWtISEiQfs7JycHRo0dRpUqVko2OiIiISIOonDg1adIEMpkMMpksz0tyBgYG+P7770s0OCIiIiJNonLidPfuXQghULNmTURERKBy5crSOl1dXVhZWUFbW7tUgiQiIiLSBConTvb29gAAuVxeasEQERERabIizxx+7do1xMbGKg0U79OnT7GDIiIiItJEaidOd+7cQb9+/fD3339DJpMhdxqo3Ekxc3JySjZCIiIiIg2h9nQEU6dORY0aNfDkyRNUrFgRV69exalTp9CsWTP8/vvvpRAiERERkWZQu8cpPDwcJ0+ehKWlJbS0tKClpYU2bdpg2bJlmDJlCv7666/SiJOIiIiozKnd45STkwNjY2MAgKWlJeLi4gC8GTweExNTstERERERaRC1e5waNWqEy5cvo0aNGnBzc8OKFSugq6uLLVu2oGbNmqURIxEREZFGUDtx+vLLL5GWlgYAWLJkCXr16oW2bdvCwsICe/fuLfEAiYiIiDSFTOTeFlcMSUlJqFSpknRn3ceguE9XJiIiovevuN/fRZ7H6W3m5uYl0QwRERGRRlMpcerfv7/KDQYHBxc5GCIiIiJNptJddaamptJiYmKC0NBQXLx4UVofGRmJ0NBQmJqallqgRERERGVNpR6n7du3S/+fM2cOBg8ejE2bNkkP9c3JycGECRM41oeIiIg+aGoPDq9cuTLOnDmDevXqKZTHxMSgVatWePbsWYkGqKk4OJyIiKj8Ke73t9oTYGZnZ+PGjRtK5Tdu3IBcLlc7ACIiIqLyQu276vz8/DBq1Cjcvn0brq6uAIDz589j+fLl8PPzK/EAiYiIiDSF2onTypUrYWNjg1WrViE+Ph4AYGtri1mzZuGzzz4r8QCJiIiINEWxJsBMTU0FgI9yjA/HOBEREZU/ZToBJhMGIiIi+piolDh98sknCA0NRaVKldC0adMCH61y6dKlEguOiIiISJOolDj17dsXenp6AABPT8/SjIeIiIhIY5XIQ34/RhzjREREVP6893mciIiIiD5WKl2qq1SpUoHjmt6WlJRUrICIiIiINJVKidPatWtLOQwiIiIizadS4jR8+PDSjoOIiIhI4xVrHqfXr18jMzNToYwDpYmIiOhDpfbg8LS0NEyaNAlWVlYwNDREpUqVFBYiIiKiD5XaidPs2bNx8uRJbNy4EXp6eti2bRsWL14MOzs77Ny5szRiJCIiItIIal+q+/XXX7Fz5064u7vDz88Pbdu2Re3atWFvb49du3Zh6NChpREnERERUZlTu8cpKSkJNWvWBPBmPFPu9ANt2rTBqVOnSjY6IiIiIg2iduJUs2ZN3L17FwDg6OiIffv2AXjTE2VmZlaiwRERERFpErUTJz8/P1y+fBkAMHfuXGzYsAH6+vqYPn06Zs2aVaQgNmzYAAcHB+jr68PNzQ0RERH51nV3d4dMJlNaevbsCQDIysrCnDlz4OTkBENDQ9jZ2cHX1xdxcXEK7Tg4OCi1sXz58iLFT0RERB8HlZ9VN3PmTIwePRqOjo4K5ffv30dkZCRq166Nxo0bqx3A3r174evri02bNsHNzQ1r165FUFAQYmJiYGVlpVQ/KSlJYQqEZ8+ewdnZGdu2bcOIESOQkpKCgQMHYsyYMXB2dsbz588xdepU5OTk4OLFi9J2Dg4OGDVqFMaMGSOVGRsbw9DQUKW4+aw6IiKi8qe4398qJ0516tTBnTt34ObmhtGjR8PLy0vlJKMgbm5uaN68OdavXw8AkMvlqFatGiZPnoy5c+cWuv3atWuxYMECxMfH5xvPhQsX4Orqivv376N69eoA3iRO06ZNw7Rp04oUNxMnIiKi8ue9PeT35s2bCAsLQ926dTF16lTY2Nhg5MiROHv2rNo7zZWZmYnIyEh4eHj8G5CWFjw8PBAeHq5SG/7+/vD29i4wiUtJSYFMJlMag7V8+XJYWFigadOm+Pbbb5GdnZ1vGxkZGUhNTVVYiIiI6OOi1hindu3aISAgAAkJCfjuu+9w8+ZNtGnTBvXr18fKlSvx+PFjtXaemJiInJwcWFtbK5RbW1sjISGh0O0jIiIQHR2N0aNH51vn9evXmDNnDnx8fBQyyylTpiAwMBBhYWEYN24cvv76a8yePTvfdpYtWwZTU1NpqVatmgpHSERERB8SlS/V5efWrVvYvn07Nm3ahJcvXyIjI0PlbePi4lClShWcPXsWLVu2lMpnz56NP/74A+fPny9w+3HjxiE8PBxXrlzJc31WVhYGDBiAhw8f4vfffy+wS+7HH3/EuHHj8PLlS+jp6Smtz8jIUDi21NRUVKtWjZfqiIiIypH3dqkuL2lpaTh9+jT++OMPPH/+XJrfSVWWlpbQ1tZW6ql6/PgxbGxsCt13YGAgRo0alef6rKwsDB48GPfv30dISEihL46bmxuys7Nx7969PNfr6enBxMREYSEiIqKPS5ESpzNnzmDkyJGwtbXFlClTULduXZw+fRrXr19Xqx1dXV24uLggNDRUKpPL5QgNDVXogcpLUFAQMjIyMGzYMKV1uUnTzZs3ceLECVhYWBQaS1RUFLS0tPK8k4+IiIgIUOORK/Hx8dixYwcCAgLwzz//oEWLFli9ejW8vb1hZGRU5ABmzJiB4cOHo1mzZnB1dcXatWuRlpYGPz8/AICvry+qVKmCZcuWKWzn7+8PT09PpaQoKysLAwcOxKVLl3DkyBHk5ORI46XMzc2hq6uL8PBwnD9/Hh06dICxsTHCw8Mxffp0DBs2jA8qJiIionypnDhVq1YNFhYW+PTTTzFq1CjUr1+/RALw8vLC06dPsWDBAiQkJKBJkyY4evSoNGA8NjYWWlqKHWMxMTE4c+YMjh8/rtTeo0ePcPjwYQBAkyZNFNaFhYXB3d0denp6CAwMxKJFi5CRkYEaNWpg+vTpmDFjRokcExEREX2YVB4cHhwcjD59+kBH599ca/ny5fi///u/j/JRK5zHiYiIqPx5bxNg5sXExARRUVFqDwr/EDBxIiIiKn/K9K66Ys5kQERERFSuFCtxIiIiIvqYqDw4PC/Xrl1DlSpVSioWIiIiIo2mdo/TgwcP8PDhQwBv7rS7ePEipk2bhi1btpR4cERERESaRO3EaciQIQgLCwMAJCQkoHPnzoiIiMAXX3yBJUuWlHiARERERJpC7cQpOjoarq6uAIB9+/ahUaNGOHv2LHbt2oWAgICSjo+IiIhIY6idOGVlZUkPwT1x4gT69OkDAHB0dER8fHzJRkdERESkQdROnBo2bIhNmzbh9OnTCAkJQbdu3QAAcXFxKj0TjoiIiKi8Ujtx+uabb7B582a4u7vDx8cHzs7OAIDDhw9Ll/CIiIiIPkRFmjk8JycHqampCg/EvXfvHipWrAgrK6sSDVBTceZwIiKi8ue9zxz+6tUrZGRkSEnT/fv3sXbtWsTExHw0SRMRERF9nNROnPr27YudO3cCAJKTk+Hm5oZVq1bB09MTGzduLPEAiYiIiDSF2onTpUuX0LZtWwDA/v37YW1tjfv372Pnzp1Yt25diQdIREREpCnUTpzS09NhbGwMADh+/Dj69+8PLS0ttGjRAvfv3y/xAImIiIg0hdqJU+3atfHLL7/gwYMHOHbsGLp06QIAePLkCQdJExER0QdN7cRpwYIFmDlzJhwcHODq6oqWLVsCeNP71LRp0xIPkIiIiEhTFGk6goSEBMTHx8PZ2RlaWm9yr4iICJiYmMDR0bHEg9REnI6AiIio/Cnu97dOUXZqY2MDGxsbPHz4EABQtWpVTn5JREREHzy1L9XJ5XIsWbIEpqamsLe3h729PczMzPDVV19BLpeXRoxEREREGkHtHqcvvvgC/v7+WL58OVq3bg0AOHPmDBYtWoTXr19j6dKlJR4kERERkSZQe4yTnZ0dNm3ahD59+iiUHzp0CBMmTMCjR49KNEBNxTFORERE5c97f+RKUlJSngPAHR0dkZSUpHYAREREROWF2omTs7Mz1q9fr1S+fv16ODs7l0hQRERERJpI7TFOK1asQM+ePXHixAlpDqfw8HA8ePAA//vf/0o8QCIiIiJNoXaPU/v27fHPP/+gX79+SE5ORnJyMvr374+YmBjpGXZEREREHyK1epyysrLQrVs3bNq0iXfPERER0UdHrR6nChUq4MqVK6UVCxEREZFGU/tS3bBhw+Dv718asRARERFpNLUHh2dnZ+PHH3/EiRMn4OLiAkNDQ4X1q1evLrHgiIiIiDSJ2olTdHQ0PvnkEwDAP//8o7BOJpOVTFREREREGkjtxCksLKw04iAiIiLSeCqPccrJycGVK1fw6tUrpXWvXr3ClStX+JBfIiIi+qCpnDj99NNPGDlyJHR1dZXWVahQASNHjsTu3btLNDgiIiIiTaJy4uTv74+ZM2dCW1tbaZ2Ojg5mz56NLVu2lGhwRERERJpE5cQpJiYGLVq0yHd98+bNcf369RIJioiIiEgTqZw4paWlITU1Nd/1L168QHp6eokERURERKSJVE6c6tSpg7Nnz+a7/syZM6hTp06JBEVERESkiVROnIYMGYIvv/wyz0euXL58GQsWLMCQIUNKNDgiIiIiTSITQghVKmZlZaFLly44c+YMPDw84OjoCAC4ceMGTpw4gdatWyMkJAQVKlQo1YA1RWpqKkxNTZGSkgITE5OyDoeIiIhUUNzvb5UTJ+BN8rRmzRrs3r0bN2/ehBACdevWxZAhQzBt2rQ8pyr4UDFxIiIiKn/ea+JE/2LiREREVP4U9/tb5TFORERERB87Jk5EREREKmLiRERERKQiJk5EREREKmLiRERERKQiHXU3yMnJQUBAAEJDQ/HkyRPI5XKF9SdPniyx4IiIiIg0idqJ09SpUxEQEICePXuiUaNGkMlkpRHXRyX1dRbSMrJha2qgtC4+5RUM9XRgov9xTCxKRESkydROnAIDA7Fv3z706NGjNOL56KS+zsLwHyPw7GUmAse2gJ3Zv8lTXPIreG85BwsjXewY6crkiYiIqIypPcZJV1cXtWvXLo1YPkppGdl49jITsUnp8N5yDnHJrwD8mzTFJqXj2ctMpGVkl3GkREREpHbi9Nlnn+G7774DJxwvGbamBggc2wLVzStKyVPk/SQpaapuXhGBY1vkeRmPiIiI3i+1H7nSr18/hIWFwdzcHA0bNlR6qG9wcHCJBqipSvqRK2/3MOXKTZrevnxHRERERVfc72+1xziZmZmhX79+au+ICmZnZoA1Xs4YsDFcKlvj5cykiYiISIPwIb9FxB4nIiKi8ocP+f0AvJ00VTeviAPjWyqMecodME5ERERlq0g9Tvv378e+ffsQGxuLzMxMhXWXLl0qseA0WUn1OMWnvILXZsWB4HZmBkrJ1N5xHCBORERUXO+9x2ndunXw8/ODtbU1/vrrL7i6usLCwgJ37txB9+7d1Q7gY2eopwMLI12ly3J2Zv/ebWdhpAtDPbWHoxEREVEJUztx+uGHH7BlyxZ8//330NXVxezZsxESEoIpU6YgJSWlSEFs2LABDg4O0NfXh5ubGyIiIvKt6+7uDplMprT07NkTAJCVlYU5c+bAyckJhoaGsLOzg6+vL+Li4hTaSUpKwtChQ2FiYgIzMzOMGjUKL1++LFL8xWGiXwE7Rrpi7zjlsUx2ZgbYO64FJ78kIiLSEGonTrGxsWjVqhUAwMDAAC9evAAAfPrpp9izZ4/aAezduxczZszAwoULcenSJTg7O6Nr16548uRJnvWDg4MRHx8vLdHR0dDW1sagQYMAAOnp6bh06RLmz5+PS5cuITg4GDExMejTp49CO0OHDsXVq1cREhKCI0eO4NSpUxg7dqza8ZcEE/0K+V6GszU1YNJERESkKYSaatSoIS5duiSEEMLFxUVs2rRJCCHEsWPHRKVKldRtTri6uoqJEydKP+fk5Ag7OzuxbNkylbZfs2aNMDY2Fi9fvsy3TkREhAAg7t+/L4QQ4tq1awKAuHDhglTnt99+EzKZTDx69Eil/aakpAgAIiUlRWnd+vXrhb29vdDT0xOurq7i/Pnz+bbTvn17AUBp6dGjhxBCiMzMTDF79mzRqFEjUbFiRWFrays+/fRTpTifPXsmhgwZIoyNjYWpqakYOXKkePHihbR+4cKFee6nYsWKKh0vERHRh6Cg729VqN3j1LFjRxw+fBgA4Ofnh+nTp6Nz587w8vJSe36nzMxMREZGwsPDQyrT0tKCh4cHwsPDC9jyX/7+/vD29oahoWG+dVJSUiCTyWBmZgYACA8Ph5mZGZo1aybV8fDwgJaWFs6fP59nGxkZGUhNTVVY8qKpPWgzZ85U2E98fDwaNGgg7YeIiIhUoG6mlZOTI7KysqSf9+zZIyZPnizWrVsnMjIy1Grr0aNHAoA4e/asQvmsWbOEq6trodufP39eACiwR+fVq1fik08+EUOGDJHKli5dKurWratUt3LlyuKHH37Is538emzezVjLSw9aVFSUACBOnTqlUlxEREQfgvfe46SlpQUdnX/v8PL29sa6deswefJk6OrqFj+TU4O/vz+cnJzg6uqa5/qsrCwMHjwYQghs3LixWPuaN28eUlJSpOXBgwdKdcpTD9q2bdtQt25dtG3bVqW4iIiIqIgTYJ4+fRrDhg1Dy5Yt8ejRIwDATz/9hDNnzqjVjqWlJbS1tfH48WOF8sePH8PGxqbAbdPS0hAYGIhRo0bluT43abp//z5CQkIU5mqwsbFRunSWnZ2NpKSkfPerp6cHExMTheVdiYmJyMnJgbW1tUK5tbU1EhISCjweAIiIiEB0dDRGjx6db53Xr19jzpw58PHxkWJISEiAlZWVQj0dHR2Ym5vnud/Xr19j165d+b52RERElDe1E6cDBw6ga9euMDAwwF9//YWMjAwAb3pBvv76a7Xa0tXVhYuLC0JDQ6UyuVyO0NBQtGzZssBtg4KCkJGRgWHDhimty02abt68iRMnTsDCwkJhfcuWLZGcnIzIyEip7OTJk5DL5XBzc1PrGErS++pBO3jwIF68eIHhw4cXuQ0iIqKPkdqJ03/+8x9s2rQJW7duRYUK/94m37p16yLNGj5jxgxs3boVO3bswPXr1zF+/HikpaXBz88PAODr64t58+Ypbefv7w9PT0+lpCgrKwsDBw7ExYsXsWvXLuTk5CAhIQEJCQnSLOf169dHt27dMGbMGERERODPP//EpEmT4O3tDTs7O7WPIVd56UHbtm0bevXqpdQzRkRERIVQd1CUgYGBuHv3rhBCCCMjI3H79m0hhBC3b98Wenp6RRpo9f3334vq1asLXV1d4erqKs6dOyeta9++vRg+fLhC/Rs3bggA4vjx40pt3b17N89B3ABEWFiYVO/Zs2fCx8dHGBkZCRMTE+Hn56dw+35h8htc5urqKiZNmiT9nJOTI6pUqVLo4PDt27cLPT09kZiYqLQuMzNTeHp6ioYNG4onT54orc8dHH7x4kWp7NixY3kODr9z546QyWTi119/Vek4iYiIPiTFHRxepHmcQkJChBCKidOOHTtE/fr1ixREeZTfCx8YGCj09PREQECAuHbtmhg7dqwwMzMTCQkJQgghPv30UzF37lyl9tq0aSO8vLyUyjMzM0WfPn1E1apVRVRUlIiPj5eWt+9i7Natm2jatKk4f/68OHPmjKhTp47w8fFRau/LL78UdnZ2Ijs7u7gvARERUblT3MRJ7QegjRkzBlOnTsWPP/4ImUyGuLg4hIeHY+bMmZg/f35JdYSVW15eXnj69CkWLFiAhIQENGnSBEePHpUui8XGxkJLS/EKaUxMDM6cOYPjx48rtffo0SNp3qwmTZoorAsLC4O7uzsAYNeuXZg0aRI6deoELS0tDBgwAOvWrVOoL5fLERAQgBEjRkBbW7uEjpiIiOjjIRNCCHU2EELg66+/xrJly5Ceng7gzR1nM2fOxFdffVUqQWqi4j5dmYiIiN6/4n5/q5045crMzMStW7fw8uVLNGjQAEZGRkVpptxi4kRERFT+FPf7W+1Ldbl0dXXRoEGDom5OREREVO6onDiNHDlSpXo//vhjkYMhIiIi0mQqJ04BAQGwt7dH06ZNUcSre0RERETlmsqJ0/jx47Fnzx7cvXsXfn5+GDZsGMzNzUszNiIiIiKNovLM4Rs2bEB8fDxmz56NX3/9FdWqVcPgwYNx7Ngx9kARERHRR6HId9Xdv38fAQEB2LlzJ7Kzs3H16tWP6s463lVHRERU/hT3+1vtZ9VJG2ppQSaTQQiBnJycojZDREREVG6olThlZGRgz5496Ny5M+rWrYu///4b69evR2xs7EfV20RERPSx2rBhAxwcHKCvrw83NzdERETkW9fd3R0ymUxp6dmzp1QnODgYXbp0gYWFBWQyGaKiovJsKzw8HB07doShoSFMTEzQrl07vHr1Slp/6dIldO7cGWZmZrCwsMDYsWPx8uXLEjvuXConThMmTICtrS2WL1+OXr164cGDBwgKCkKPHj2UHiFCREREH569e/dixowZWLhwIS5dugRnZ2d07doVT548ybN+cHAw4uPjpSU6Ohra2toYNGiQVCctLQ1t2rTBN998k+9+w8PD0a1bN3Tp0gURERG4cOECJk2aJOUfcXFx8PDwQO3atXH+/HkcPXoUV69exYgRI0r0+AE1xjhpaWmhevXqaNq0KWQyWb71goODSyw4TcYxTkRE9LFxc3ND8+bNsX79egBvnoFarVo1TJ48GXPnzi10+7Vr12LBggWIj4+HoaGhwrp79+6hRo0a+Ouvv5SezdqiRQt07tw530e7bdmyBfPnz0d8fLyUTP39999o3Lgxbt68idq1a0t139sYJ19fX3To0AFmZmYwNTXNdyEiIqIPT2ZmJiIjI+Hh4SGVaWlpwcPDA+Hh4Sq14e/vD29vb6WkqSBPnjzB+fPnYWVlhVatWsHa2hrt27fHmTNnpDoZGRnQ1dVVuAJmYGAAAAr1SoJaE2ASERHRxykxMRE5OTmwtrZWKLe2tsaNGzcK3T4iIgLR0dHw9/dXa7937twBACxatAgrV65EkyZNsHPnTnTq1AnR0dGoU6cOOnbsiBkzZuDbb7/F1KlTkZaWJvWAxcfHq7W/wnBwEhEREZU6f39/ODk5wdXVVa3t5HI5AGDcuHHw8/ND06ZNsWbNGtSrV096zFvDhg2xY8cOrFq1ChUrVoSNjQ1q1KgBa2vrEh+HzcSJiIiICmVpaQltbW08fvxYofzx48ewsbEpcNu0tDQEBgZi1KhRau/X1tYWANCgQQOF8vr16yM2Nlb6eciQIUhISMCjR4/w7NkzLFq0CE+fPkXNmjXV3mdBmDgRERFRoXR1deHi4oLQ0FCpTC6XIzQ0FC1btixw26CgIGRkZGDYsGFq79fBwQF2dnaIiYlRKP/nn39gb2+vVN/a2hpGRkbYu3cv9PX10blzZ7X3WRCVxzgRERHRx23GjBkYPnw4mjVrBldXV6xduxZpaWnw8/MD8OZGsipVqmDZsmUK2/n7+8PT0xMWFhZKbSYlJSE2NhZxcXEAICVINjY2sLGxgUwmw6xZs7Bw4UI4OzujSZMm2LFjB27cuIH9+/dL7axfvx6tWrWCkZERQkJCMGvWLCxfvhxmZmYl+howcSIiIiKVeHl54enTp1iwYAESEhLQpEkTHD16VBowHhsbqzSmKCYmBmfOnMHx48fzbPPw4cNS4gUA3t7eAICFCxdi0aJFAIBp06bh9evXmD59OpKSkuDs7IyQkBDUqlVL2i4iIgILFy7Ey5cv4ejoiM2bN+PTTz8tycMHUIxn1X3sOI8TERFR+VNmz6ojIiIi+tgwcSIiIiJSERMnIiIiIhUxcSIiIiJSERMnIiIiIhUxcSIiIiJSERMnIiIiIhUxcSIiIiJSERMnIiIiIhUxcSIiIiJSERMnIiIiKnOpr7MQn/Iqz3XxKa+Q+jrrPUeUNyZOREREVKZSX2dh+I8R8Np8DnHJislTXPIreG0+h+E/RmhE8sTEiYiIiMpUWkY2nr3MRGxSOry3/Js8xSW/gveWc4hNSsezl5lIy8gu40iZOBEREVEZszU1QODYFqhuXlFKniLvJ0lJU3Xziggc2wK2pgZlHSpkQghR1kGUR6mpqTA1NUVKSgpMTEzKOhwiIqJy7+0eply5SZOdWckkTcX9/maPExEREWkEOzMDrPFyVihb4+VcYklTSWDiRERERBohLvkVpu+9rFA2fe9lpQHjZYmJExEREZW5ty/TVTeviAPjWyqMedKU5ImJExEREZWp+JRXSgPBXezNlQaM5zfP0/vExImIiIjKlKGeDiyMdJUGgtuZ/Xu3nYWRLgz1dMo4Ut5VV2S8q46IiKjkpL7OQlpGdp5TDsSnvIKhng5M9CsUfz/F/P4u+9SNiIiIPnom+hXyTYw0Yf6mXLxUR0RERKQiJk5EREREKmLiREQq27BhAxwcHKCvrw83NzdERETkW9fd3R0ymUxp6dmzp1QnODgYXbp0gYWFBWQyGaKiovJtTwiB7t27QyaT4ZdffsmzzrNnz1C1alXIZDIkJycX8SiJiPLHxImIVLJ3717MmDEDCxcuxKVLl+Ds7IyuXbviyZMnedYPDg5GfHy8tERHR0NbWxuDBg2S6qSlpaFNmzb45ptvCt3/2rVrIZPJCqwzatQoNG7cWL0DIyJSAweHE5FKVq9ejTFjxsDPzw8AsGnTJvz3v//Fjz/+iLlz5yrVNzc3V/g5MDAQFStWVEicPv30UwDAvXv3Ctx3VFQUVq1ahYsXL8LW1jbPOhs3bkRycjIWLFiA3377TZ1DIyJSGXuciKhQmZmZiIyMhIeHh1SmpaUFDw8PhIeHq9SGv78/vL29YWhoqNa+09PTMWTIEGzYsAE2NjZ51rl27RqWLFmCnTt3QkuLH2tEVHr4CUNEhUpMTEROTg6sra0Vyq2trZGQkFDo9hEREYiOjsbo0aPV3vf06dPRqlUr9O3bN8/1GRkZ8PHxwbfffovq1aur3T4RkTp4qY6ISp2/vz+cnJzg6uqq1naHDx/GyZMn8ddff+VbZ968eahfvz6GDRtW3DCJiArFHiciKpSlpSW0tbXx+PFjhfLHjx/ne/ksV1paGgIDAzFq1Ci193vy5Encvn0bZmZm0NHRgY7Om7/1BgwYAHd3d6lOUFCQtL5Tp05SzAsXLlR7n0REBWGPExEVSldXFy4uLggNDYWnpycAQC6XIzQ0FJMmTSpw26CgIGRkZBSpR2ju3LlKl/ecnJywZs0a9O7dGwBw4MABvHr174M/L1y4gJEjR+L06dOoVauW2vskIioIEyciUsmMGTMwfPhwNGvWDK6urli7di3S0tKku+x8fX1RpUoVLFu2TGE7f39/eHp6wsLCQqnNpKQkxMbGIi4uDgAQExMDALCxsVFY3lW9enXUqFEDAJSSo8TERABA/fr1YWZmVryDJiJ6BxMnIlKJl5cXnj59igULFiAhIQFNmjTB0aNHpQHjsbGxSne0xcTE4MyZMzh+/HiebR4+fFhKvADA29sbALBw4UIsWrSodA6EiKgYZEIIUdZBlEfFfboyERERvX/F/f7m4HAiIiIiFTFxIiIiIlJRmSdOZfHQ0Lza+b//+7/SODwiIiL6gJRp4lSWDw0dM2aMQlsrVqwo0WMjIiKiD0+Z3lVXlg8NrVixYqET9xERERG9rcx6nMryoaEAsGvXLlhaWqJRo0aYN28e0tPT1W6DiIiIPi5l1uNU0ENDb9y4Uej2uQ8N9ff3V3vfQ4YMgb29Pezs7HDlyhXMmTMHMTExCA4OznebjIwMZGRkSD+npqaqvV8iIiIq38rtBJhFfWgoAIwdO1b6v5OTE2xtbdGpUyfcvn0730c0LFu2DIsXLy5yvERERFT+ldmlurJ6aGhe3NzcAAC3bt3Kt868efOQkpIiLQ8ePCiRfRMREVH5UWaJ09sPDc2V+9DQli1bFrhtcR4ampfcKQtsbW3zraOnpwcTExOFhYiIiD4uZXqpriweGnr79m3s3r0bPXr0gIWFBa5cuYLp06ejXbt2aNy4cSkfMRHlJ/V1FtIysmFraqC0Lj7lFQz1dGCiX6EMIiMi+leZJk5l8dBQXV1dnDhxQkrSqlWrhgEDBuDLL78spaMkosKkvs7C8B8j8OxlJgLHtoCd2b/JU1zyK3hvOQcLI13sGOnK5ImIyhQf8ltEfMgvUcmJT3kFr83nEJuUjurmFaXkKTdpyi3fO65Fnj1SRESq4kN+iajcszU1QODYFqhuXhGxSenw3nIOkfeTFJKmwLFMmoio7LHHqYjY40RU8t7uYcr1dg8UEVFxsceJiD4YdmYGWOPlrFC2xsuZSRMRaQwmTkSkMeKSX2H63ssKZdP3XkZc8qsyioiISBETJyLSCO8OBD8wvqXCmCcmT0SkCZg4EVGZi095pTQQ3MXeXGnAeHwKkyciKltMnIiozBnq6cDCSFdpILid2b9321kY6cJQr9w+XpOIPhC8q66IeFcdUcnizOFE9D4U9/ubf74RkUYw0a+Qb2LE+ZuISFPwUh0RERGRipg4EREREamIiRMRERGRipg4EREREamIiRMRERGRipg4EREREamIiRMRERGRipg4EREREamIiRMRERGRijhzeBHlPqkmNTW1jCMhIiIiVeV+bxf1iXNMnIroxYsXAIBq1aqVcSRERESkrhcvXsDU1FTt7fiQ3yKSy+WIi4uDsbExZDJZibWbmpqKatWq4cGDBx/tw4P5GhDPAaKPW2l+Bggh8OLFC9jZ2UFLS/0RS+xxKiItLS1UrVq11No3MTH56L8w+BoQzwGij1tpfQYUpacpFweHExEREamIiRMRERGRipg4aRg9PT0sXLgQenp6ZR1KmeFrQDwHiD5umvwZwMHhRERERCpijxMRERGRipg4EREREamIiRMRERGRipg4EREREamIidN7curUKfTu3Rt2dnaQyWT45ZdfpHVZWVmYM2cOnJycYGhoCDs7O/j6+iIuLk6hjX/++Qd9+/aFpaUlTExM0KZNG4SFhb3nIymaZcuWoXnz5jA2NoaVlRU8PT0RExOjUMfd3R0ymUxh+b//+z+ltgICAtC4cWPo6+vDysoKEydOfF+HQUW0aNEipd+to6OjtH7Lli1wd3eHiYkJZDIZkpOTFba/d+8eRo0ahRo1asDAwAC1atXCwoULkZmZ+Z6PhIhUVdD3HvBmBu8FCxbA1tYWBgYG8PDwwM2bN6X16r7vb926BWNjY5iZmZXiUTFxem/S0tLg7OyMDRs2KK1LT0/HpUuXMH/+fFy6dAnBwcGIiYlBnz59FOr16tUL2dnZOHnyJCIjI+Hs7IxevXohISHhfR1Gkf3xxx+YOHEizp07h5CQEGRlZaFLly5IS0tTqDdmzBjEx8dLy4oVKxTWr169Gl988QXmzp2Lq1ev4sSJE+jatev7PBQqooYNGyr8bs+cOSOtS09PR7du3fD555/nue2NGzcgl8uxefNmXL16FWvWrMGmTZvyrU9EZa+g7z0AWLFiBdatW4dNmzbh/PnzMDQ0RNeuXfH69WsA6r3vs7Ky4OPjg7Zt25bqMQEABL13AMTBgwcLrBMRESEAiPv37wshhHj69KkAIE6dOiXVSU1NFQBESEhIaYZbKp48eSIAiD/++EMqa9++vZg6dWq+2yQlJQkDAwNx4sSJ9xAhlaSFCxcKZ2fnQuuFhYUJAOL58+eF1l2xYoWoUaNG8YMjolL37veeXC4XNjY24ttvv5XKkpOThZ6entizZ0++7eT3vp89e7YYNmyY2L59uzA1NS3J0JWwx0lDpaSkQCaTSV2OFhYWqFevHnbu3Im0tDRkZ2dj8+bNsLKygouLS9kGWwQpKSkAAHNzc4XyXbt2wdLSEo0aNcK8efOQnp4urQsJCYFcLsejR49Qv359VK1aFYMHD8aDBw/ea+xUNDdv3oSdnR1q1qyJoUOHIjY2tljtpaSkKJ0/RFQ+3L17FwkJCfDw8JDKTE1N4ebmhvDw8Hy3y+t9f/LkSQQFBeXbs1XS+JBfDfT69WvMmTMHPj4+0sMNZTIZTpw4AU9PTxgbG0NLSwtWVlY4evQoKlWqVMYRq0cul2PatGlo3bo1GjVqJJUPGTIE9vb2sLOzw5UrVzBnzhzExMQgODgYAHDnzh3I5XJ8/fXX+O6772Bqaoovv/wSnTt3xpUrV6Crq1tWh0SFcHNzQ0BAAOrVq4f4+HgsXrwYbdu2RXR0NIyNjdVu79atW/j++++xcuXKUoiWiEpb7hATa2trhXJra+t8h5/k9b5/9uwZRowYgZ9//vm9PRCciZOGycrKwuDBgyGEwMaNG6VyIQQmTpwIKysrnD59GgYGBti2bRt69+6NCxcuwNbWtgyjVs/EiRMRHR2tMMYFAMaOHSv938nJCba2tujUqRNu376NWrVqQS6XIysrC+vWrUOXLl0AAHv27IGNjQ3CwsI41kmDde/eXfp/48aN4ebmBnt7e+zbtw+jRo1Sq61Hjx6hW7duGDRoEMaMGVPSoRKRBsrvfT9mzBgMGTIE7dq1e2+x8FKdBslNmu7fv4+QkBCF7PnkyZM4cuQIAgMD0bp1a3zyySf44YcfYGBggB07dpRh1OqZNGkSjhw5grCwMFStWrXAum5ubgDe/JUBQEoOGzRoINWpXLkyLC0ti33Zh94vMzMz1K1bV/rdqiouLg4dOnRAq1atsGXLllKKjohKm42NDQDg8ePHCuWPHz+W1uUq6H1/8uRJrFy5Ejo6OtDR0cGoUaOQkpICHR0d/Pjjj6USOxMnDZGbNN28eRMnTpyAhYWFwvrcsT5aWoq/Mi0tLcjl8vcWZ1EJITBp0iQcPHgQJ0+eRI0aNQrdJioqCsC/CVPr1q0BQGEag6SkJCQmJsLe3r7kg6ZS8/LlS9y+fVutntJHjx7B3d0dLi4u2L59u9J7gYjKjxo1asDGxgahoaFSWWpqKs6fP4+WLVtKZYW978PDwxEVFSUtS5YsgbGxMaKiotCvX79SiZ2X6t6Tly9fKvx1fffuXURFRcHc3By2trYYOHAgLl26hCNHjiAnJ0e6xmtubg5dXV20bNkSlSpVwvDhw7FgwQIYGBhg69atuHv3Lnr27FlWh6WyiRMnYvfu3Th06BCMjY2l4zM1NYWBgQFu376N3bt3o0ePHrCwsMCVK1cwffp0tGvXDo0bNwYA1K1bF3379sXUqVOxZcsWmJiYYN68eXB0dESHDh3K8vCoEDNnzkTv3r1hb2+PuLg4LFy4ENra2vDx8QHwZrxDQkKC9B75+++/YWxsjOrVq8Pc3Fz68LS3t8fKlSvx9OlTqe13/zolIs1Q0Pde9erVMW3aNPznP/9BnTp1UKNGDcyfPx92dnbw9PQEAJXe9/Xr11fY58WLF6GlpaUwfrbEleo9eyTJvc363WX48OHi7t27ea4DIMLCwqQ2Lly4ILp06SLMzc2FsbGxaNGihfjf//5XdgelhvyOb/v27UIIIWJjY0W7du2Eubm50NPTE7Vr1xazZs0SKSkpCu2kpKSIkSNHCjMzM2Fubi769esnYmNjy+CISB1eXl7C1tZW6OrqiipVqggvLy9x69Ytaf3ChQsLPD+2b9+e7zlERJqpoO89Id5MSTB//nxhbW0t9PT0RKdOnURMTIy0fVHe9+9jOgKZEEKUXlpGRERE9OHgIAEiIiIiFTFxIiIiIlIREyciIiIiFTFxIiIiIlIREyciIiIiFTFxIiIiIlIREyciIiIiFTFxIqKPUkBAAMzMzEq83UWLFqFJkyYl3i4RaQYmTkRUZkaMGAGZTCYtFhYW6NatG65cuaJWO+8zWTl48CBatGgBU1NTGBsbo2HDhpg2bZq0fubMmQrP3yKiDwsTJyIqU926dUN8fDzi4+MRGhoKHR0d9OrVq6zDylNoaCi8vLwwYMAAREREIDIyEkuXLkVWVpZUx8jISOkh3UT04WDiRERlSk9PDzY2NrCxsUGTJk0wd+5cPHjwQOGBnnPmzEHdunVRsWJF1KxZE/Pnz5eSlYCAACxevBiXL1+Weq4CAgIAAMnJyRg3bhysra2hr6+PRo0a4ciRIwr7P3bsGOrXrw8jIyMpicvPr7/+itatW2PWrFmoV68e6tatC09PT2zYsEGq827v19s9armLg4ODtD46Ohrdu3eHkZERrK2t8emnnyIxMVFav3//fjg5OcHAwAAWFhbw8PBAWlpaUV5qIioBTJyISGO8fPkSP//8M2rXrq3Qa2NsbIyAgABcu3YN3333HbZu3Yo1a9YAALy8vPDZZ5+hYcOGUs+Vl5cX5HI5unfvjj///BM///wzrl27huXLl0NbW1tqNz09HStXrsRPP/2EU6dOITY2FjNnzsw3PhsbG1y9ehXR0dEqH1NuTPHx8bh16xZq166Ndu3aAXiT2HXs2BFNmzbFxYsXcfToUTx+/BiDBw+WtvXx8cHIkSNx/fp1/P777+jfvz/4iFGiMlSqjxAmIirA8OHDhba2tjA0NBSGhoYCgLC1tRWRkZEFbvftt98KFxcX6eeFCxcKZ2dnhTrHjh0TWlpaCk9bf1vuk9dv3bollW3YsEFYW1vnu9+XL1+KHj16CADC3t5eeHl5CX9/f/H69esCYxHizZPg+/XrJ1xcXER6eroQQoivvvpKdOnSRaHegwcPBAARExMjIiMjBQBx7969fGMioveLPU5EVKY6dOiAqKgoREVFISIiAl27dkX37t1x//59qc7evXvRunVr2NjYwMjICF9++SViY2MLbDcqKgpVq1ZF3bp1861TsWJF1KpVS/rZ1tYWT548ybe+oaEh/vvf/+LWrVv48ssvYWRkhM8++wyurq5IT08vMJ7PP/8c4eHhOHToEAwMDAAAly9fRlhYGIyMjKTF0dERAHD79m04OzujU6dOcHJywqBBg7B161Y8f/68wP0QUeli4kREZcrQ0BC1a9dG7dq10bx5c2zbtg1paWnYunUrACA8PBxDhw5Fjx49cOTIEfz111/44osvkJmZWWC7uclJQSpUqKDws0wmU+kyWK1atTB69Ghs27YNly5dwrVr17B379586//8889Ys2YNDh48iCpVqkjlL1++RO/evaXEMXe5efMm2rVrB21tbYSEhOC3335DgwYN8P3336NevXq4e/duoTESUenQKesAiIjeJpPJoKWlhVevXgEAzp49C3t7e3zxxRdSnbd7owBAV1cXOTk5CmWNGzfGw4cP8c8//xTY61RcDg4OqFixYr4DtsPDwzF69Ghs3rwZLVq0UFj3ySef4MCBA3BwcICOTt4fxzKZDK1bt0br1q2xYMEC2Nvb4+DBg5gxY0aJHwsRFY6JExGVqYyMDCQkJAAAnj9/jvXr10s9MQBQp04dxMbGIjAwEM2bN8d///tfHDx4UKENBwcH3L17V7o8Z2xsjPbt26Ndu3YYMGAAVq9ejdq1a+PGjRuQyWTo1q1bkWJdtGgR0tPT0aNHD9jb2yM5ORnr1q1DVlYWOnfurFQ/ISEB/fr1g7e3N7p27Sodp7a2NipXroyJEydi69at8PHxwezZs2Fubo5bt24hMDAQ27Ztw8WLFxEaGoouXbrAysoK58+fx9OnT1G/fv0ixU9ExcdLdURUpo4ePQpbW1vY2trCzc0NFy5cQFBQENzd3QEAffr0wfTp0zFp0iQ0adIEZ8+exfz58xXaGDBgALp164YOHTqgcuXK2LNnDwDgwIEDaN68OXx8fNCgQQPMnj1bqWdKHe3bt8edO3fg6+sLR0dHdO/eHQkJCTh+/Djq1aunVP/GjRt4/PgxduzYIR2jra0tmjdvDgCws7PDn3/+iZycHHTp0gVOTk6YNm0azMzMoKWlBRMTE5w6dQo9evRA3bp18eWXX2LVqlXo3r17kY+BiIpHJlS5oE9ERERE7HEiIiIiUhUTJyIiIiIVMXEiIiIiUhETJyIiIiIVMXEiIiIiUhETJyIiIiIVMXEiIiIiUhETJyIiIiIVMXEiIiIiUhETJyIiIiIVMXEiIiIiUhETJyIiIiIV/T8p7eDyaZdQZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean cross-validation accuracies on the final epoch for different batch sizes\n",
    "plt.scatter(batch_sizes_list, mean_cv_accuracies, marker='x')\n",
    "plt.xlabel('Batch Sizes')\n",
    "plt.ylabel('Mean Cross-Validation Accuracy')\n",
    "plt.title('Mean Cross-Validation Accuracy On Final Epoch vs Batch Size')\n",
    "plt.xticks(batch_sizes_list)\n",
    "\n",
    "# Add labels to each data point\n",
    "for i, txt in enumerate(mean_cv_accuracies):\n",
    "    if i == 2 or i == 3:\n",
    "        plt.text(batch_sizes_list[i] - 10, mean_cv_accuracies[i] + 0.0012, round(txt, 4), ha='center')  \n",
    "    else:\n",
    "        plt.text(batch_sizes_list[i] + 10, mean_cv_accuracies[i] - 0.0012, round(txt, 4), ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f305ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time Taken to Train the Network on the Last Epoch Across 5 Folds Against Different Batch Sizes:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Mean Time Taken for Last Epoch Across 5 Folds (seconds)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.4051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.1939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Mean Time Taken for Last Epoch Across 5 Folds (seconds)\n",
       "0         128                                             0.4051      \n",
       "1         256                                             0.2824      \n",
       "2         512                                             0.2159      \n",
       "3        1024                                             0.1939      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Please note that the next time you run this notebook cell, the results will be different as time taken depends on CPU speed and other factors.\n",
    "\n",
    "# Calculate mean time for the last epoch for each batch size\n",
    "mean_last_epoch_times_list = [round(sum(cross_validation_times[batch_size]) / len(cross_validation_times[batch_size]),4) for batch_size in batch_sizes_list]\n",
    "\n",
    "# Create a table of time taken to train the network on the last epoch against different batch sizes\n",
    "time_df = pd.DataFrame({\n",
    "    'Batch Size': batch_sizes_list,\n",
    "    'Mean Time Taken for Last Epoch Across 5 Folds (seconds)': mean_last_epoch_times_list\n",
    "})\n",
    "\n",
    "print(\"Mean Time Taken to Train the Network on the Last Epoch Across 5 Folds Against Different Batch Sizes:\")\n",
    "print()\n",
    "display(time_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b93a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal batch size: 256\n",
      "\n",
      "Reason: \n",
      "\n",
      "Given the balance of accuracy and speed, the Batch Size of 256 emerges as the optimal choice.\n",
      "\n",
      "Selection of Optimal Batch Size:\n",
      "\n",
      "    • Selecting the appropriate batch size is a crucial step in the optimization of neural networks. The goal is to find an equilibrium that harmonizes both computational efficiency \n",
      "    and model accuracy. Intuitively, as batch size increases, training tends to be swifter due to enhanced parallelism and optimized matrix operations, resulting in a higher throughput \n",
      "    of computations. However, excessively large batch sizes may reduce the stochastic nature of gradient descent, potentially leading to a compromise in accuracy as we can see in the \n",
      "    results above. Additionally, it is also important to note that the trends are not definitive for the entire dataset as we are only calculating the mean values of the last epoch over the 5 folds\n",
      "    for each batch size. Thus, the results may vary if we take the mean values of all the epochs instead.\n",
      "\n",
      "From the data:\n",
      "\n",
      "    • Batch Size of 128: This size is the second most accurate, coming in at 0.7207. However, this heightened accuracy comes at the cost of time, as it is much slower relative to \n",
      "    the batch size of 256, taking about 0.4051 seconds.\n",
      "\n",
      "    • Batch Size of 256: Presents itself as the optimal choice. Its accuracy is the highest at 0.7387 by quite a large margin. Moreover, its efficiency shines through, clocking in a time of \n",
      "    0.2824 seconds. It offers the best trade-off between performance and speed.\n",
      "\n",
      "    • Batch Sizes of 512 and 1024: As the batch sizes increase, we note a clear decline in accuracy. Although the batch size of 512 is faster than the first two at 0.2159 seconds, its \n",
      "    accuracy drops to 0.7144. Similarly, a batch size of 1024 is the fastest but has a lower accuracy of 0.7169 compared to a batch size of 256.\n",
      "\n",
      "Conclusion:\n",
      "\n",
      "    • While the batch size of 128 has a competitive accuracy, the performance of 256 with a higher accuracy and reasonable computation time stands out. The difference in accuracy \n",
      "    between 128 and 256 is quite large and the increase in efficiency with 256 is significant. Furthermore, as we increase the batch size beyond this point, the reductions in time do not \n",
      "    compensate for the drops in accuracy, particularly at 512 and 1024. Thus, the batch size of 256 provides the most balanced outcome in the context of our data, combining \n",
      "    together swift training with robust performance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 256\n",
    "reason = '''\n",
    "\n",
    "Given the balance of accuracy and speed, the Batch Size of 256 emerges as the optimal choice.\n",
    "\n",
    "Selection of Optimal Batch Size:\n",
    "\n",
    "    • Selecting the appropriate batch size is a crucial step in the optimization of neural networks. The goal is to find an equilibrium that harmonizes both computational efficiency \n",
    "    and model accuracy. Intuitively, as batch size increases, training tends to be swifter due to enhanced parallelism and optimized matrix operations, resulting in a higher throughput \n",
    "    of computations. However, excessively large batch sizes may reduce the stochastic nature of gradient descent, potentially leading to a compromise in accuracy as we can see in the \n",
    "    results above. Additionally, it is also important to note that the trends are not definitive for the entire dataset as we are only calculating the mean values of the last epoch over the 5 folds\n",
    "    for each batch size. Thus, the results may vary if we take the mean values of all the epochs instead.\n",
    "\n",
    "From the data:\n",
    "\n",
    "    • Batch Size of 128: This size is the second most accurate, coming in at 0.7207. However, this heightened accuracy comes at the cost of time, as it is much slower relative to \n",
    "    the batch size of 256, taking about 0.4051 seconds.\n",
    "\n",
    "    • Batch Size of 256: Presents itself as the optimal choice. Its accuracy is the highest at 0.7387 by quite a large margin. Moreover, its efficiency shines through, clocking in a time of \n",
    "    0.2824 seconds. It offers the best trade-off between performance and speed.\n",
    "\n",
    "    • Batch Sizes of 512 and 1024: As the batch sizes increase, we note a clear decline in accuracy. Although the batch size of 512 is faster than the first two at 0.2159 seconds, its \n",
    "    accuracy drops to 0.7144. Similarly, a batch size of 1024 is the fastest but has a lower accuracy of 0.7169 compared to a batch size of 256.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "    • While the batch size of 128 has a competitive accuracy, the performance of 256 with a higher accuracy and reasonable computation time stands out. The difference in accuracy \n",
    "    between 128 and 256 is quite large and the increase in efficiency with 256 is significant. Furthermore, as we increase the batch size beyond this point, the reductions in time do not \n",
    "    compensate for the drops in accuracy, particularly at 512 and 1024. Thus, the batch size of 256 provides the most balanced outcome in the context of our data, combining \n",
    "    together swift training with robust performance.\n",
    "'''\n",
    "\n",
    "print(f\"Optimal batch size: {optimal_batch_size}\")\n",
    "print()\n",
    "print(f\"Reason: {reason}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78876fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
